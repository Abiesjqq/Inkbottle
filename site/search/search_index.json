{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hi, visitor","text":"Hi, this is Abies |"},{"location":"CS231n/assignments/a1_knn/","title":"KNN","text":""},{"location":"CS231n/assignments/a1_knn/#compute-distances","title":"Compute Distances","text":""},{"location":"CS231n/assignments/a1_knn/#two-loops","title":"Two Loops","text":"<p>Implement the function compute_distances_two_loops that uses a (very inefficient) double loop over all pairs of (test, train) examples and computes the distance matrix one element at a time.</p> <p>If there are Ntr training examples and Nte test examples, this stage should result in a Nte x Ntr matrix where each element (i,j) is the distance between the i-th test and j-th train example.</p> <pre><code>def compute_distances_two_loops(self, X):\n    \"\"\"\n    Inputs:\n    - X: A numpy array of shape (num_test, D) containing test data.\n\n    Returns:\n    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n      is the Euclidean distance between the ith test point and the jth training\n      point.\n    \"\"\"\n    num_test = X.shape[0]\n    num_train = self.X_train.shape[0]\n    dists = np.zeros((num_test, num_train))\n    for i in range(num_test):\n        for j in range(num_train):\n            dists[i, j] = np.sqrt(np.sum(np.square(self.X_train[j, :] - X[i, :])))\n\n    return dists\n</code></pre>"},{"location":"CS231n/assignments/a1_knn/#one-loop","title":"One Loop","text":"<pre><code>def compute_distances_one_loop(self, X):\n    num_test = X.shape[0]\n    num_train = self.X_train.shape[0]\n    dists = np.zeros((num_test, num_train))\n    for i in range(num_test):\n        dists[i, :] = np.sqrt(np.sum(np.square(self.X_train - X[i, :]), axis=1))\n\n    return dists\n</code></pre>"},{"location":"CS231n/assignments/a1_knn/#no-loops","title":"No Loops","text":"<p>Principles:</p> \\[\\|\\mathbf{x}-\\mathbf{y}\\|=\\|\\mathbf{x}\\|^2+\\|\\mathbf{y}\\|^2-2\\mathbf{x}^T \\mathbf{y}\\] <pre><code>def compute_distances_no_loops(self, X):\n    num_test = X.shape[0]\n    num_train = self.X_train.shape[0]\n    dists = np.zeros((num_test, num_train))\n\n    M = -2 * np.dot(X, self.X_train.T)\n    M_train = np.array([np.sum(np.square(self.X_train), axis=1).T])\n    M_test = np.array([np.sum(np.square(X))]).T\n    dists = np.sqrt(M + M_train + M_test)\n\n    return dists\n</code></pre>"},{"location":"CS231n/assignments/a1_knn/#predict-labels","title":"Predict Labels","text":"<pre><code>def predict_labels(self, dists, k=1):\n    \"\"\"\n    Given a matrix of distances between test points and training points,\n    predict a label for each test point.\n\n    Inputs:\n    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n        gives the distance between the ith test point and the jth training point.\n\n    Returns:\n    - y_pred: A numpy array of shape (num_test,) containing predicted labels\n      for the test data, where y_pred[i] is the predicted label for test point X[i].\n    \"\"\"\n\n    num_test = dists.shape[0]\n    y_pred = np.zeros(num_test)\n\n    for i in range(num_test):\n        closest_y = []\n\n        row = dists[i, :]\n        sorted_indices = np.argsort(row)  # Indices that sort the distances (small to large)\n\n        # Pick the labels of the k nearest neighbors\n        for index in range(k):\n            closest_y.append(self.y_train[sorted_indices[index]])\n\n        # Count the occurrences of each label among the k nearest neighbors\n        counts = {}\n        for element in closest_y:\n            if element not in counts:\n                counts[element] = 1\n            else:\n                counts[element] += 1\n\n        # Determine final label by majority vote\n        label = 0\n        for key in counts:\n            if label not in counts:            # If label hasn't been assigned yet\n                label = key\n            if counts[key] &gt; counts[label]:    # Found a label with higher count\n                label = key\n            if counts[key] == counts[label] and key &lt; label:\n                label = key\n\n        y_pred[i] = label\n\n    return y_pred\n\n</code></pre>"},{"location":"CS231n/assignments/a1_knn/#other-operations","title":"Other Operations","text":""},{"location":"CS231n/assignments/a1_knn/#subsample-the-data","title":"Subsample the Data","text":"<p>Subsample the data for more efficient code execution in this exercise.</p> <pre><code># Pick out the first 5000 training samples\nnum_training = 5000\nmask = list(range(num_training))\nX_train = X_train[mask]\ny_train = y_train[mask]\n\n# Pick out the first 500 testing samples\nnum_test = 500\nmask = list(range(num_test))\nX_test = X_test[mask]\ny_test = y_test[mask]\n\n# Reshape the image data into rows\nX_train = np.reshape(X_train, (X_train.shape[0], -1))\nX_test = np.reshape(X_test, (X_test.shape[0], -1))\nprint(X_train.shape, X_test.shape)\n</code></pre>"},{"location":"CS231n/assignments/a1_knn/#cross-validation","title":"Cross-validation","text":"<pre><code>num_folds = 5\nk_choices = [1, 3, 5, 8, 10, 12, 15, 20, 50, 100]\n\nX_train_folds = []\ny_train_folds = []\nX_train_folds = np.array_split(X_train, num_folds)\ny_train_folds = np.array_split(y_train, num_folds)\n\nk_to_accuracies = {}\n\nfor k in k_choices:\n    for i in range(num_folds):\n        validation_X = X_train_folds[i]\n        validation_y = y_train_folds[i]\n        train_X = np.concatenate(X_train_folds[:i] + X_train_folds[i + 1:])\n        train_y = np.concatenate(y_train_folds[:i] + y_train_folds[i + 1:])\n\n        Classifier = KNearestNeighbor()\n        Classifier.train(train_X, train_y)\n        y_prediction = Classifier.predict_labels(validation_X, k=k)\n\n        NumCorrect = np.sum(y_prediction == validation_y)\n        acc = float(NumCorrect) / len(validation_X)\n        if i == 0:\n            k_to_accuracies[k] = []\n        k_to_accuracies[k].append(acc)\n\n# Print out the computed accuracies\nfor k in sorted(k_to_accuracies):\n    for accuracy in k_to_accuracies[k]:\n        print('k = %d, accuracy = %f' % (k, accuracy))\n\n</code></pre>"},{"location":"CS231n/assignments/a1_softmax/","title":"A1 softmax","text":""},{"location":"CS231n/assignments/a1_softmax/#calculate-softmax-loss","title":"Calculate Softmax Loss","text":""},{"location":"CS231n/assignments/a1_softmax/#naive-computation","title":"Naive computation","text":"<pre><code>def softmax_loss_naive(W, X, y, reg):\n    \"\"\"\n    Softmax loss function, naive implementation (with loops)\n\n    Inputs have dimension D, there are C classes, and we operate on minibatches\n    of N examples.\n\n    Inputs:\n    - W: A numpy array of shape (D, C) containing weights.\n    - X: A numpy array of shape (N, D) containing a minibatch of data.\n    - y: A numpy array of shape (N,) containing training labels; y[i] = c means\n      that X[i] has label c, where 0 &lt;= c &lt; C.\n    - reg: (float) regularization strength\n\n    Returns a tuple of:\n    - loss as single float\n    - gradient with respect to weights W; an array of same shape as W\n    \"\"\"\n    # Initialize the loss and gradient to zero.\n    loss = 0.0\n    dW = np.zeros_like(W)\n\n    num_train = X.shape[0]\n    num_class = W.shape[1]\n    scores = X.dot(W)\n    scores = np.exp(scores - np.max(scores))\n    p = scores / np.sum(scores, axis=1).reshape(num_train, 1)\n\n    for i in range(num_train):\n        loss -= np.log(p[i][y[i]])\n        for j in range(num_class):\n            if j == y[i]:\n                dW[:, j] += (p[i][j] - 1) * X[i].T\n            else:\n                dW[:, j] += p[i][j] * X[i].T\n    loss /= num_train\n    loss += reg * np.sum(W * W)\n\n    dW /= num_train\n    dW += 2 * reg * W\n    return loss, dW\n</code></pre>"},{"location":"CS231n/notes/cs231n_02/","title":"Lec1 Image Classification","text":""},{"location":"CS231n/notes/cs231n_02/#about-the-dataset","title":"About the dataset","text":"<p>The dataset is CIFAR-10, which contains 10 categories of images.</p>"},{"location":"CS231n/notes/cs231n_02/#two-functions-train-and-predict","title":"Two functions: train and predict","text":"<p><code>train</code> is used to memorize and fit the training data.</p> <p><code>predict</code> takes a new image and the number <code>k</code>, finds the nearest neighbors, and outputs the predicted label.</p>"},{"location":"CS231n/notes/cs231n_02/#comparing-a-new-image-with-its-k-nearest-neighbors","title":"Comparing a new image with its k nearest neighbors","text":"<p>L1 distance (Manhattan): sum the absolute difference of every corresponding pixel value. Issue: each pixel only affects the result locally, so it is sensitive to noise. Fix: use more neighbors <code>k</code>; adding weights can average out noise so decision boundaries become smoother.</p> <p>L2 distance (Euclidean): square the difference in every dimension and then sum. Large deviations on any pixel get magnified, so it is even more affected by outliers than L1.</p> <p>k-NN is generally slow at query time and very sensitive to irrelevant or noisy features; high dimensionality worsens this.</p>"},{"location":"CS231n/notes/cs231n_02/#choosing-hyperparameters","title":"Choosing hyperparameters","text":"<p>Hyperparameters are set before learning; the question is how to choose them. We can try different values, but judging them by training accuracy alone can be misleading because we care about performance on unseen data.</p> <p>So we split data into train, validation, and test: train on train, evaluate hyperparameters on validation to pick the best setting, then run once on test to report results.</p> <p>Another option is cross-validation: split data into a series of folds; in each round choose one fold as validation and train on the others, then average the results. This is common on small datasets.</p>"},{"location":"CS231n/notes/cs231n_02/#parametric-model","title":"Parametric model","text":"<p>A parametric model is \\(f(x, W)\\), composed of input \\(x\\) (an image) and weights \\(W\\) that produce scores for each class. For example, \\(f(x, W) = W x + b\\). Suppose there are \\(n\\) pixels and \\(m\\) classes: \\(x\\) is \\(n \\times 1\\), \\(W\\) is \\(m \\times n\\) with one row per class storing its weights, the output \\(f(x, W)\\) is a score vector, and \\(b\\) is \\(n \\times 1\\).</p> <p>In k-nearest neighbors, test time depends on all training samples. In a parametric model, the training phase stores knowledge in \\(W\\), so at test time only \\(W\\) is needed.</p> <p>An image is a point in a high-dimensional space. A linear classifier draws hyperplanes to divide the space into regions assigned to different categories. However, some problems (e.g., judging whether a number is even or odd) are not linearly separable, so a linear classifier cannot solve them.</p>"},{"location":"CS231n/notes/cs231n_03/","title":"Lec2 Loss Functions and Optimization","text":""},{"location":"CS231n/notes/cs231n_03/#loss-function-svm-loss","title":"Loss Function: SVM Loss","text":"<p>For the N training samples \\((x_i, y_i)\\), define the per-sample loss \\(L_i\\) and the total loss as the average</p> \\[L = \\frac{1}{N} \\sum_i L_i(f(x_i, W), y_i)\\] <p>Our goal is to minimize this L.</p> <p>SVM loss: each class gets a score. The correct class score should be higher than all others by at least a margin; outside the margin the loss is zero, inside the margin the loss grows with the violation.</p> <p>E.g., with a margin of 1 (\\(s\\) denotes the vector of scores):</p> \\[L_i = \\displaystyle \\sum_{j \\neq y_i} \\begin{cases} 0, &amp; s_{y_i} \\ge s_j + 1 \\\\ s_j - s_{y_i} + 1, &amp; \\text{otherwise} \\end{cases}\\] <p>Early in training\uff0c scores are near 0, so loss is roughly <code>(#classes - 1)</code>. The minimum loss is 0; if a \\(W\\) achieves zero loss then any scaled version like \\(2W\\) also does.</p> <p>We do not only care about fitting training labels; we want good test performance. A model that fits train data too aggressively may generalize poorly. Therefore we add a regularization term \\(\\lambda R(W)\\) to the loss to trade off margin against model simplicity so that \\(W\\) does not become arbitrarily complex.</p> <p>Common regularizers:</p> <ul> <li>L2: \\(R(W) = \\sum_k \\sum_l W_{k,l}^2\\)</li> <li>L1: \\(R(W) = \\sum_k \\sum_l |W_{k,l}|\\)</li> <li>Elastic net (L1 + L2): \\(R(W) = \\sum_k \\sum_l \\left(\\beta W_{k,l}^2 + |W_{k,l}|\\right)\\)</li> </ul>"},{"location":"CS231n/notes/cs231n_03/#loss-function-softmax-loss","title":"Loss Function: Softmax Loss","text":"<p>This is the loss for the Softmax classifier (multinomial logistic regression). In SVM we only enforce that the correct class out-scores others by a margin. In Softmax, scores are mapped to class probabilities.  </p> <p>Definition of probability:</p> \\[P(Y = k \\mid X = x_i) = \\frac{e^{s_k}}{\\sum_j e^{s_j}}\\] <p>Where \\(s = f(x_i; W)\\) and exponentiation makes every entry positive. We want the probability of the correct class to be high; the loss is the negative log-likelihood:</p> \\[L_i = -\\log P(Y = y_i \\mid X = x_i)\\] <p>Exponentiated scores define a distribution; minimizing the loss maximizes the probability of the correct class.</p> <p>SVM loss only pushes the correct score above others by the margin; Softmax loss not only wants it higher but as high as possible. In practice, Softmax often works better.</p>"},{"location":"CS231n/notes/cs231n_03/#finding-w-via-gradient-descent","title":"Finding W via Gradient Descent","text":"<p>Different \\(W\\) give different loss; optimization searches for \\(W\\) that minimizes loss.</p> <p>Gradient of \\(f\\): \\(\\nabla f = \\left(\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z}\\right)\\). Gradient descent moves against the gradient of the loss with respect to \\(W\\) to approach a minimum. To get the gradient numerically, add a small \\(h\\) to each element of \\(W\\), measure the change in loss, and approximate \\(\\mathrm{d}W\\); this is numerical gradient checking. Writing the exact derivative formula is the analytic gradient.</p> <p>Gradient descent pseudocode:</p> <pre><code>while True:\n    weights_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weights_grad\n</code></pre> <p>Stochastic Gradient Descent (SGD): computing the full loss gradient can be expensive; when loss is an average we can approximate its gradient using only part of the data.</p> \\[\\nabla_W L(W) = \\frac{1}{N} \\sum_{i=1}^N \\nabla_W L_i(x_i, y_i, W) + \\lambda \\nabla_W R(W)\\] <p>Vanilla minibatch gradient descent: instead of all data, randomly pick a small set (e.g., 256 samples) as a minibatch to estimate the gradient.</p>"},{"location":"CS231n/notes/cs231n_03/#feature-extraction-for-image-matching","title":"Feature Extraction for Image Matching","text":"<p>In practice, raw pixels vary a lot; we often extract features before matching. If two images contain the same object but at different positions, a linear classifier on raw pixels fails because translation moves the pattern across the grid. Better features include color histograms and Histogram of Oriented Gradients (HoG). Another approach: sample patches to build a codebook (visual words); for a new image, encode patches by the nearest codebook words and pool those counts into features.</p>"},{"location":"CS231n/notes/cs231n_04/","title":"Lec3 Introduction to Neural Networks","text":""},{"location":"CS231n/notes/cs231n_04/#backpropagation","title":"Backpropagation","text":"<p>The forward pass uses a computation graph to store intermediate values. The backward pass starts from the end node and uses those saved values to compute the gradient of each node with respect to the loss by applying the chain rule. For a node with inputs (x, y) and output z, each node performs a simple operation; its local gradients \\(\\frac{\\partial z}{\\partial x}\\) and \\(\\frac{\\partial z}{\\partial y}\\) are easy to compute. Once we have \\(\\frac{\\partial L}{\\partial z}\\) from downstream, the chain rule gives \\(\\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial z} \\cdot \\frac{\\partial z}{\\partial x}\\), which is then passed to the previous node.</p> <p>Each node keeps and passes on its local gradient. For a max node, the input that wins gets gradient 1, the others get 0; the local gradient depends on which input was largest.</p> <p>Why is backprop more efficient than directly differentiating \\(L\\) with respect to every parameter? Because the chain rule lets us reuse local gradients; we only need each node\u2019s small derivative.</p> <p>You can treat several simple units as one larger operation, e.g., bundling nodes into a sigmoid \\(\\sigma(x) = \\frac{1}{1 + e^{-x}}\\).</p> <p>When inputs are high-dimensional, the local gradient (Jacobian) is often sparse. Example: a 4096-D ReLU layer \\(f(x) = \\max(0, x)\\) outputs 4096-D. Its Jacobian is 4096\u00d74096; entry (i, j) is how output i changes with input j. For ReLU each output depends only on its matching input, so only the diagonal matters.</p> <p>Backprop illustration:</p> <p>{style=\"width:550px\"}</p>"},{"location":"CS231n/notes/cs231n_04/#neural-networks","title":"Neural Networks","text":"<p>Single-layer linear model: \\(f = W x\\). Two-layer example: \\(f = W_2 \\max(0, W_1 x)\\); stacking layers with nonlinearity increases expressive power. W2 can assign different weights to different templates learned in W1.</p> <p>Neural-network terminology comes from biology but the analogy is weak: dendrites multiply by weights \\(w_i x_i\\), the cell body sums them, and the axon applies a nonlinearity \\(f\\!\\left(\\sum_i w_i x_i + b_i\\right)\\).</p> <p>Common activation functions: Sigmoid, Leaky ReLU, tanh, Maxout, ReLU, ELU, etc. Architectures have an input layer, an output layer, and hidden layers in between. Example:</p> <pre><code>x = np.random.randn(3, 1)\nh1 = f(np.dot(W1, x) + b1)\nh2 = f(np.dot(W2, h1) + b2)\nout = np.dot(W3, h2) + b3\n</code></pre>"},{"location":"CS231n/notes/cs231n_05/","title":"Lec4 Convolutional Neural Networks","text":""},{"location":"CS231n/notes/cs231n_05/#convolutional-neural-network","title":"Convolutional Neural Network","text":"<p>Fully connected layer: take 32x32x3 image for example. Stretch it to 3072x1 vector, do dot product with 10x3072 weight matrix, and get 1x10 activation.</p> <p>Convolution layer: preserve the spacial structure. Keep the image as 32x32x3, concolve a 5x5x3 filter with the image. The depths of filter and image are always the same (3 here). Convolve: overlay the filter on top of a spacial location in the image, multiply corresponding elements and add bias.</p> <p>How to slide the filter? Center the filter on top of every pixel in the input volumn. The activation map will be smaller than the input, in 32x32x3 image and 5x5x3 filter case, activation map will be 28x28x1.</p> <p>Each filter is looking for some specific type of template or concept. E.g., when applying 6 filters, the activation map becomes 28x28x6.</p> <ul> <li>CONV: extract features with filters (as above)</li> <li>RELU: nonlinear activation applied after CONV</li> <li>POOL: downsample the activation map, applied after RELU.</li> </ul> <p>ConvNet is a sequence of convolutional layers. Each output is the input of the next layer.</p> <p>Depth of activation map?</p> <p>If the depth of input image is n, corresponding element in output is the sum of n convolving result. Therefore each filter produce a 2D map.</p> <p>What do filter image represent?</p> <p>If we treat filter as grayscale image, each filter can be visualized as a small patch with properties like stripes, edges or textures. Images with vertical stripes detect horizontal edges, images with oriented stripes detect oriented edges, etc.</p> <p>These images show the input pattern that maximizes the activation of the filter.</p> <p>Other options: slide the filter with different strides. Larger stride, smaller output. If strides doesn't fit the input, dismiss this option.</p> <p>In practice, pad the input image with zeros (or other values) to maintain full size.</p> <p>Calculate parameters</p> <p>Input volumn: 32x32x3, 10 5x5 filters with stride 1, pad 2. What's the number of parameters in this layer?</p> <p>For each filter, \\(5\\times 5\\times 3=75\\) weights and \\(1\\) bias.</p> <p>Total parameters: \\((75+1)\\times 10=760\\).</p> <p>Pooling layer: make the map smaller and more managable. Commom methods include max pooling (find the maximum in a region) and average pooling (calculate the average of a region). Now people use strides more instead of pooling?  </p> <p>Fully connected layer (FC layer): aggregate the result into a 1D vector.</p>"},{"location":"CS231n/notes/cs231n_06/","title":"Lec5 Training Neural Networks I","text":""},{"location":"CS231n/notes/cs231n_06/#activation-functions","title":"Activation Functions","text":"<p>Sigmoid: squashes numbers to range [0,1].</p> \\[\\sigma(x)=\\frac{1}{1+e^{-x}}\\] <p>3 problems:</p> <ol> <li>Saturated neurons \"kill\" the gradients. (When x is very negtive or very positive, sigmoid function is flat, so the gradient on x is nearly zero, which kill the upstream gradient.)</li> <li>Sigmoid outputs are not zero-centered. (When the input to a neuron is always positive, the gradients on w are always all positive or all negative, because the gradient of sigmoid function is always positive.)</li> <li>exp() is a bit compute expensive.</li> </ol> <p>tanh: squashes numbers to range [-1,1].</p> <p>tanh(x) s zero centered, but still kills gradients when saturated.</p> <p>ReLU:</p> \\[f(x)=\\max(0,x)\\] <p>ReLU does not saturated in +region, very computationally efficient, converges faster than sigmoid/tanh, and more biologically paulsible.</p> <p>2 problems:</p> <ol> <li>Not zero-centered.</li> <li>Kill the gradients in -region.</li> </ol> <p>Positive ReLU: cross the data cloud. Some data falls in the +region and output a positive value. Dead ReLU: off the data cloud. The data always falls in the negtive region.</p> <p>In practice, people like to initialize ReLU neurons with slightly positive bias (e.g. 0.01).</p> <p>Leaky ReLU:</p> \\[f(x)=\\max(0.01x, x)\\] <p>Compared to ReLU, leaky ReLU will not \"die\" in the negative region.</p> <p>Parametric Rectifier (PReLU):</p> \\[f(x)=\\max(\\alpha x, x)\\] <p>Treat \\(\\alpha\\) as a parameter that we can backprop and learn.</p> <p>Exponential Linear Units (ELU):</p> \\[ f(x)=\\begin{cases}x &amp;\\text{if}\\, x&gt;0 \\\\ \\alpha (\\text{exp}(x)-1) &amp;\\text{if}\\, x\\le 0\\end{cases} \\] <p>ELU has all benefits of ReLU, closer to zero mean outputs, and its negative saturation regime compared with Leaky ReLU adds some robustness to noise.</p> <p>Problem: computaion requires exp().</p> <p>Maxout \"Neuron\": contains multiple linear transformations. Its output is the maximum among them.</p> \\[\\max(w_1^Tx+b_1,w_2^Tx+b_2)\\] <p>Problem: double the number of parameters per neuron.</p> <p>In practice:</p> <ul> <li>Use ReLU. Be careful with your learning rates.</li> <li>Try out Leaky ReLU / Maxout / ELU.</li> <li>Try out tanh but don't expect much.</li> <li>Don't use sigmoid.</li> </ul>"},{"location":"CS231n/notes/cs231n_06/#data-preprocessing","title":"Data Preprocessing","text":"<p>Data preprocessing is for zero mean.</p> <p>original data --&gt; zero-centered data --&gt; normalized data</p> <p>May also see PCA and Whitening of the data: original data --&gt; decorrelated data --&gt; whitened data.</p>"},{"location":"CS231n/notes/cs231n_06/#weight-initailization","title":"Weight Initailization","text":"<p>What happends when W=0 init is used? All neurons do the same thing and update in the same.</p> <p>First idea: set all weights small random numbers. (Gaussian with zero mean and 1e-2 standard deviation.) <code>W = 0.01 * np.random.rand(D, H)</code> Problem: in deeper networks, the signal is continuously reduced at each layer, eventually all activations become zero.</p> <p>Second idea: use 1.0 instead of 0.01. But almost all neurions completely saturated, either 1 or -1 (using tanh). Gradients will be all zero.</p> <p>Xavier initialization:</p> <p><code>W = np.random.rand(fan_in, fan_out) / np.sqrt(fan_in)</code></p> <p>Reasonable when using tanh, but break when using ReLU. Can use <code>np.sqrt(fan_in / 2)</code> instead of <code>np.sqrt(fan_in)</code>.</p>"},{"location":"CS231n/notes/cs231n_06/#batch-normalization","title":"Batch Normalization","text":"<p>Consider a batch of catications at some layer. To make each dimension unit gaussian, apply:</p> \\[\\hat{x}^{(k)}=\\frac{x^{(k)}-\\mathrm{E}[x^{(k)}]}{\\sqrt{\\mathrm{Var}[x^{(k)}]}}\\] <p>Consider the input of N batch, and each batch has dimension D. First compute the empirical mean and variance independently for each dimension, and then normalize.</p> <p>BN is usually inserted after Fully Connected or Convolutional layers, and before nonlinearity.</p> <p>Squash the range if it wants to:</p> \\[y^{(k)}=\\gamma^{(k)}\\hat{x}^{(k)}+\\beta^{(k)}\\] <p>The network can learn \\(\\gamma^{(k)}=\\sqrt{\\mathrm{Var}[x^{(k)}]}\\), \\(\\beta^{(k)}=\\mathrm{E}[x^{(k)}]\\) to recover the identity mapping.</p>"},{"location":"CS231n/notes/cs231n_06/#babysitting-the-learning-process","title":"Babysitting the Learning Process","text":"<ol> <li>Preprocess the data.</li> <li>Choose the architecture.</li> <li>Double check that the loss os reasonable.</li> <li>Try training. Start with small regularization and find learning rate that makes the loss go down.</li> </ol> <p>Rough range for learning rate wo should be cross-validating is somewhere [1e-3 ... 1e-5].</p>"},{"location":"CS231n/notes/cs231n_06/#hyperparameter-optimization","title":"Hyperparameter Optimization","text":"<p>Hyperparameters to play with: netword architecture, learning rate, decay schedule, update type, regularization...</p> <p>Cross-validation strategy: coarse --&gt; fine cross-validation in stages.</p> <p>Note it's best to optimize in log space.</p> <p>In practice, it's better to sample with random layout than with grid layout.</p>"},{"location":"CS231n/notes/cs231n_07/","title":"Lec6 Training Neural Networks II","text":""},{"location":"CS231n/notes/cs231n_07/#improve-optimization","title":"Improve Optimization","text":"<pre><code>while True:\n    weights_grad = evaluate_gradient(loss_fun, data, weights)\n    weights += -step_size * weights_grad\n</code></pre> <p>Problem:</p> <ol> <li>Loss function sensitive in one direction but not in another direction. SGD will have zigzag bahavior.</li> <li>The loss function has a local minima or saddle point (in higher space, loss go up in some directions and down in other directions). SGD will get stuck.</li> <li>Our gradients come from minibatches so they can be noisy.</li> </ol> <p>SGD + Momentum:</p> <pre><code>vx = 0\nwhile True:\n    dx = compute_gradient(x)\n    vx = rho * vx + dx\n    x += learning_rate * vx\n</code></pre> <p>Nesterov Momentum: First step in the direction os velocity, then compute the gradient at the new position.</p> <pre><code>dx = compute_gradient(x)\nold_v = v\nv = rho * v - learning_rate * dx\nx += -rho * old_v + (1 + rho) * v\n</code></pre> <p>AdaGrad: add element-wise scaling of the gradient based on the historical sum of squares in wach dimension.</p> <p>The sum get larger and the step get slower. Its good in convex case but not in non-convex case.</p> <pre><code>grad_squared = 0\nwhile True:\n    dx = compute_gradient(x)\n    grad_squared += dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n</code></pre> <p>RMSProp: adjust to let the square estimate decay.</p> <pre><code>grad_squared = 0\nwhile True:\n    dx = compute_gradient(x)\n    grad_squared = decay_rate * grad_squared + (1 - decay_rate) * dx * dx\n    x -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)\n</code></pre> <p>Adam: combine momentum and AdsGrad/RMSProp.</p> <p>To avoid a very large step at the beginning (becouse beta2 is close to one and second_moment is small in the first loop), add unbias terms.</p> <pre><code>first_moment = 0\nsecond_moment = 0\nwhile True:\n    dx = compute_gradient(x)\n    first_moment = beta1 * first_moment + (1 - beta1) * dx\n    second_moment = beta2 * second_moment + (1 - beta2) * dx * dx\n    first_unbias = first_moment / (1 - beta1 ** t)\n    second_unbias = second_moment / (1 - beta2 ** t)\n    x -= learning_rate * forst_moment / (np.sqrt(second_moment) + 1e-7)\n</code></pre> <p>Adam with beta1 = 0.9, beta2 = 0.999, and learning_rate = 1e-3 or 5e-4 is a great starting point for many models.</p> <p>Learning rate can decay over time, which is especially common in momentum. E.g., exponential decay: \\(\\alpha=\\alpha_0e^{-kt}\\).</p> <p>Second-order optimization:</p> <ul> <li>First-order optimization: use gradient form linear approximation; step to minimize the approximation.</li> <li>Second-order optimization: use gradient and Hessian to form quadratic approximation; step to minima of the approximation.</li> </ul> <p>Second-order Taylor expansion:</p> \\[J(\\theta)\\approx J(\\theta_0)+(\\theta-\\theta_0_^T\\nabla_{\\theta})J(\\theta_0)+\\frac{1}{2}(\\theta-\\theta_0)^T H(\\theta-\\theta_0).\\] <p>Solving for the critical point we obtain the Newton parameter update:</p> \\[\\theta^*=\\theta_0-H^{-1}\\nabla_{\\theta}J(\\theta_0).\\] <p>Quasi-Newton methods (BGFS most popular): instead of invertin the Hessian (\\(O(n^3)\\)), approximate inverse Hessian with rank 1 updates over time (\\(O(n^2)\\) each).</p> <p>L-BFGS: does not form/store the full inverse Hessian.</p>"},{"location":"CS231n/notes/cs231n_07/#improve-performance","title":"Improve Performance","text":"<p>Model ensembles: train multiple independent models. At test time averafe their results. Instead of training independent models, we can also use multiple snapshots of a single model during training.</p> <p>Polyak averaging: keep a moving average of the parameter vector and use that at test time.</p> <p>Regularizarion: add term to loss.</p> <p>Dropout: in each forward pass, randomly set some neurons to zero. Probability of dropping is a hyperparameter.</p> <p>Dropout on training a large ensemble of models that share parameters. Each binary mask is one model. At test time, multiply by dropout probability.</p> <p>Data augmentation: random flips, crops, scales, color jitters of images.</p> <p>Dropconnect: randomly zero out some oh the values of the weights matrix.</p> <p>Fraction max pooling, stochastic depth...</p>"},{"location":"CS231n/notes/cs231n_07/#transfer-learning","title":"Transfer Learning","text":"<p>Situation: train on large imagenet, and use on small dataset.</p> <p>Freeze the weights of previous layers, and only reinitialize the last matrix.</p> very similar dataset very different dataset very little data Use Linear Classifier on top layer You're in trouble... Try linear classifier from different stages quite a lot of data Finetune a few layers Finetune a larger number of layers"},{"location":"CS231n/notes/cs231n_08/","title":"Cs231n 08","text":""},{"location":"CS231n/notes/cs231n_08/#cpu-vs-gpu","title":"CPU vs GPU","text":"<p>Differences:</p> <ul> <li>CPU: fewer cores, but each core is much faster and much more capable; has small cache while the majority of memory is in RAM; great at sequaltial tasks.</li> <li>GPU: more cores, but each core is much slower and \"dumber\"; has its own RAM built and cacheing system; great for parallel tasks (matrix multiplication, convolution, etc.).</li> </ul> <p>Programming GPU: CUDA (cuDNN and other optimiazed APIs), OpenCL.</p> <p>If you aren't careful, training can bottleneck on reading data and transfering to GPU! Solution: read all data from RAM; use SSD instead of HDD; use multiple CPU threads to prefetch data.</p>"},{"location":"CS231n/notes/cs231n_08/#deep-learning-frameworks","title":"Deep Learning Frameworks","text":"<p>One goal of deep learning frameworks: enable vectors to calculate on GPU, automatically do back propagation and gradient process...</p>"},{"location":"CS231n/notes/cs231n_08/#tensorflow","title":"Tensorflow","text":"<p>Framework of Tensorflow:</p> <pre><code>initialize N, D, H\nx/y/w1/w2 = tf.placeholder(tf.float32, shape)\n\ninitialize h as x * w1\ninitialize y_pred as h * w2\nset loss as Euclidien distance\n\ngrad_w1, grad_w2 = tf.gradients(loss, [w1, w2])\n\nwith tf.Session() as sess:\n    set values as {x, w1, w2, y}\n    initialize learing_rate\n    for t in range(50):\n        out = sess.run([loss, grad_w1, grad_w2], feed_dict = values)\n        loss_val, grad_w1_val, grad_w2_val = out\n        update values[w1] and values[w2]\n</code></pre> <p>Change w1 and w2 from <code>placeholder</code> to <code>Variable</code> (values live inside the graph) to avoid GPU bottlemeck. Tensorflow should use <code>assign</code> function to initialize them.</p>"},{"location":"GAMES101/Lecture%2001%20Overview%20of%20Computer%20Graphics/","title":"Lec1 Overview of Computer Graphics","text":"<p>Menu of this lecture</p> <ul> <li>Concepts of raterization, ray tracing etc.</li> </ul>"},{"location":"GAMES101/Lecture%2001%20Overview%20of%20Computer%20Graphics/#basic-concepts","title":"Basic Concepts","text":"<p>Rasterization</p> <ol> <li>Project geometry primitives (3D triangles / polygons) onto the screen.</li> <li>Break projected primitives into fragments (pixels)</li> <li>Real-time applications is the gold standard in Video Games</li> </ol> translation <ol> <li>\u5c06\u51e0\u4f55\u5f62\u72b6\uff083D \u4e09\u89d2\u5f62/\u591a\u8fb9\u5f62\uff09\u6295\u5f71\u5230\u5c4f\u5e55\u4e0a</li> <li>\u5c06\u6295\u5f71\u540e\u7684\u56fe\u5143\u5212\u5206\u4e3a\u7247\u6bb5\uff08\u50cf\u7d20\uff09</li> <li>\u5728\u89c6\u9891\u6e38\u620f\u4e2d\uff0c\u5b9e\u65f6\u5e94\u7528\u662f\u9ec4\u91d1\u6807\u51c6</li> </ol> <p>Curves and Meshes</p> <p>Ray Tracing</p> <p>Shoot rays from camera through each pixel Offline application is the gold standard in Animation / Movies</p> <p>Animation / Simulation</p> <p>Difference between Computer Graphics and Computer Vision?</p> <p>{style=\"width:600px\"}</p> <p>Click here to jump to the course website</p>"},{"location":"GAMES101/Lecture%2002%20Review%20of%20Linear%20Algebra/","title":"Lec2 eview of Linear Algebra","text":"<p>Menu of this lecture</p> <ul> <li>Functions of dot product and cross product</li> <li>Dot product and cross product in matrix</li> </ul> <p>Unit vector: \\(\\hat{a}=\\vec{a}/|\\vec{a}|\\) Usually use unit vectors to present directions.</p> <p>Vectors are represented as column vectors by default.</p>"},{"location":"GAMES101/Lecture%2002%20Review%20of%20Linear%20Algebra/#functions-of-dot-product-and-cross-product","title":"Functions of dot product and cross product","text":"<p>Dot product:</p> <ol> <li>Find the angle between two vectors.    e.g cosine of angle bwtween light source and surface.</li> <li>Find projection of one vector on another.</li> </ol> <p>More specifically:</p> <ol> <li>Measure how close two directions are.</li> <li>Decompose a vector.</li> <li>Determine forward / backward.</li> </ol> <p>Cross product:</p> <ol> <li>Construction coordinate systems.</li> </ol> <p>Functions:</p> <ol> <li>Determine left / right. Given a plane and two vectors on this plane, determine the relative position of the two vectors.</li> <li>Determine in / out. Several vectors are connected head-to-tail to form a closed shape. Given another point, determine whether this point lies inside the closed shape.</li> </ol> <p>e.g. {style=\"width:100px\"} Check: \\(\\vec{AB}\\times\\vec{AP}, \\vec{BC}\\times\\vec{BP}, \\vec{CA}\\times\\vec{CP}\\). If the signs of all three are the same, then point P is inside the shape.</p>"},{"location":"GAMES101/Lecture%2002%20Review%20of%20Linear%20Algebra/#dot-product-and-cross-product-in-matrix","title":"Dot product and cross product in matrix:","text":"<p>2D reflection about y-axis:</p> \\[ \\begin{pmatrix} -1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix}= \\begin{pmatrix} -x \\\\ y \\end{pmatrix} \\] matrix in latex <p><code>\\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix}</code></p> <p>Rendered output:</p> \\[ \\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix} \\] \\[ \\vec{a}\\cdot\\vec{b}=A^T\\cdot B =\\begin{pmatrix} x_a &amp; y_a &amp; z_a \\end{pmatrix} \\begin{pmatrix} x_b \\\\ y_b \\\\ z_b \\end{pmatrix} \\] \\[ \\vec{a}\\times\\vec{b}=A^*B =\\begin{pmatrix}  0 &amp; -z_a &amp; y_a \\\\  z_a &amp; 0 &amp; -x_a \\\\  -y_a &amp; x_a &amp; 0  \\end{pmatrix}  \\begin{pmatrix}  x_b \\\\ y_b \\\\ z_b  \\end{pmatrix} \\] <p>(\\(\\begin{pmatrix}   0 &amp; -z_a &amp; y_a \\\\  z_a &amp; 0 &amp; -x_a \\\\  -y_a &amp; x_a &amp; 0  \\end{pmatrix}\\) is the dual matrix of \\(\\vec{a}\\))</p>"},{"location":"GAMES101/Lecture%2003%20Transformation/","title":"Lec3 Transformation","text":"<p>Menu of this lecture</p> <ul> <li>2D transformations: rotation, scale, shear</li> <li>Homogeneous coordinates</li> <li>Composing transformation</li> </ul>"},{"location":"GAMES101/Lecture%2003%20Transformation/#viewing-transformation","title":"Viewing transformation","text":"<p>Viewing transformation: 3D -&gt; 2D projection</p> <p>Scale</p> \\[ \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} =\\begin{pmatrix} s_x &amp; 0 \\\\ 0 &amp; s_y \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\] <p>Multiplying a matrix on the left corresponds to performing a row operation.</p> <p>Reflection</p> <p>E.g. reflection about the y-axis:</p> \\[ \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} =\\begin{pmatrix} -1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\] <p>Sheer</p> <p>Illustration of sheer tranformation: {style=\"width:500px\"}</p> \\[ \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} =\\begin{pmatrix} x+ay \\\\ y \\end{pmatrix} =\\begin{pmatrix} 1 &amp; a \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\] <p>Rotation</p> <p>By default, the rotation is around the origin. \\(R_{45}\\) refers to rotatiing 45 degrees counterclockwose about the origin. </p> \\[ R_{\\theta}=\\begin{pmatrix} \\cos\\theta &amp; -\\sin\\theta \\\\ \\sin\\theta &amp; \\cos\\theta \\end{pmatrix} \\]"},{"location":"GAMES101/Lecture%2003%20Transformation/#homogeneous-coordinates","title":"Homogeneous Coordinates","text":"<p>Translation is not linear transform, so it cannot be represented in matrix form.  But we don't want it to be a special case, so homogeneous coordinates are used to represent all transformations. </p> <p>Add a third coordinate (w-coordinate), to represent the translation characters of points or vectors.  </p> <p>Affine transformations: affine map = linear map + translation map  </p> \\[ \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} =\\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} +\\begin{pmatrix} t_x \\\\ t_y \\end{pmatrix} \\]"},{"location":"GAMES101/Lecture%2003%20Transformation/#2d-version","title":"2D version","text":"<ul> <li>2D point: \\(\\begin{pmatrix}x , y , 1 \\end{pmatrix}^T\\)</li> <li>2D vector:\\(\\begin{pmatrix}x , y , 0 \\end{pmatrix}^T\\)</li> </ul> <p>When \\(w\\neq 0\\), 2D point \\(\\begin{pmatrix}x , y , w \\end{pmatrix}^T\\) means \\(\\begin{pmatrix}x/w , y/w , 1 \\end{pmatrix}^T\\)</p> <p>(The w-coordinate of vectors are 0, which means vectors are translation invariant. By comparison, w-coordinate of points are 1)</p> <p>Use homogeneous Coordinates to represent affine translations:</p> \\[ \\begin{pmatrix} x' \\\\ y' \\\\ w' \\end{pmatrix} =\\begin{pmatrix} 1 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; t_y \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ 1 \\end{pmatrix} =\\begin{pmatrix} x+t_x \\\\ y+t_y \\\\ 1 \\end{pmatrix} \\] <p>Properties:  1. The last row must be 0 0 1. 2. The top-left 2\u00d72 matrix represents a linear transformation. 3. The rightmost column represents translation. 4. Relations between points and vectors:    - vector + vector = vector    - point  - point  = vector    - point  + vector = point    - point  + point  = point</p> <p>Scale:</p> \\[ S(s_x, s_y)=\\begin{pmatrix} s_x &amp; 0 &amp; 0 \\\\ 0 &amp; s_y &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Rotation:</p> \\[ R(\\alpha)=\\begin{pmatrix} \\cos\\alpha &amp; -\\sin\\alpha &amp; 0 \\\\ \\sin\\alpha &amp; \\cos\\alpha &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Translation:</p> \\[ T(t_x, t_y)=\\begin{pmatrix} 1 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; t_y \\\\  0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Inverse transformations: \\(M^{-1}\\)</p> <p>Esp. matrix \\(R_{\\theta}\\) for rotation is orthogonal, so \\(R_{-\\theta}=R^{-1}=R^T\\).</p>"},{"location":"GAMES101/Lecture%2003%20Transformation/#3d-version","title":"3D version","text":"<ul> <li>3D point: \\(\\begin{pmatrix}x , y , z, 1 \\end{pmatrix}^T\\)</li> <li>3D vector:\\(\\begin{pmatrix}x , y , z, 0 \\end{pmatrix}^T\\)</li> </ul> <p>Use 4\u00d74 matrix for affine transformations. </p>"},{"location":"GAMES101/Lecture%2003%20Transformation/#composing-transforms","title":"Composing Transforms","text":"<p>All matrices are left-multiplied to the original coordinates, and are composed in the order of transformations from right to left.</p> <p>Examples</p> <p>Transformations: A1 -&gt; A2 -&gt; ... -&gt; An Matrix: \\(A_n\\cdots A_2A_1\\begin{pmatrix}x \\\\ y \\\\ 1\\end{pmatrix}\\)</p>"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/","title":"Lec4 Transformations Cont.","text":"<p>Menu of this lecture</p> <ul> <li>3D transformations</li> <li>Viewing transformations</li> </ul>"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#3d-transformations","title":"3D Transformations","text":"<p>Scale:</p> \\[ S(s_x, s_y, s_z)= \\begin{pmatrix} s_x &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; s_y &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; s_z &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Translation:</p> \\[ T(t_x, t_y, t_z)= \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; 0 &amp; t_y \\\\ 0 &amp; 0 &amp; 1 &amp; t_z \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\]"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#3d-rotations","title":"3D Rotations","text":""},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#compose-from-r_x-r_y-r_z","title":"Compose from \\(R_x, R_y, R_z\\)","text":"\\[ R_x(\\theta)=\\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\cos\\theta &amp; -\\sin\\theta &amp; 0 \\\\ 0 &amp; \\sin\\theta &amp; \\cos\\theta &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] \\[ R_y(\\theta)=\\begin{pmatrix} \\cos\\theta &amp; 0 &amp; \\sin\\theta &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ -\\sin\\theta &amp; 0 &amp; \\cos\\theta &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>The rotation part of \\(R_y(\\theta)\\) is different from common rotation matrix, because \\(\\vec{y}=\\vec{z}\\times\\vec{x}\\), which is not the common sequence xyzxyz.</p> \\[ R_z(\\theta)=\\begin{pmatrix} \\cos\\theta &amp; -\\sin\\theta &amp; 0 &amp; 0 \\\\ \\sin\\theta &amp; \\cos\\theta &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>When rotating around x-, y-, and z- axis with angle \\(\\alpha, \\beta, \\gamma\\) respectively (\\(\\alpha, \\beta, \\gamma\\) are called Euler angles), </p> \\[ R_{xyz}(\\alpha, \\beta, \\gamma)=R_x(\\alpha)R_y(\\beta)R_z(\\gamma) \\]"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#rodrigues-rotation-formation","title":"Rodrigues' Rotation Formation","text":"<p>Rotation by angle \\(\\alpha\\) around axis n,</p> \\[ R(n, \\alpha)=\\cos(\\alpha)I+(1-\\cos(\\alpha))n n^T+\\sin(\\alpha)\\begin{pmatrix} 0 &amp; -n_z &amp; n_y \\\\ n_z &amp; 0 &amp; -n_x \\\\ -n_y &amp; n_x &amp; 0 \\end{pmatrix} \\] <p>If the axis of rotation does not pass through the origin, first translate the entire system so that the axis passes through the origin, perform the rotation, and then translate the entire system back to its original position.</p> <p>Quaternions can be used for interpolation between rotation angles.</p>"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#viewing-transformations","title":"Viewing transformations","text":"<p>MVP Transformations:</p> <ol> <li>Model transformations (arrange objects and places)</li> <li>View transformations (arrange angles)</li> <li>Projection transformations</li> </ol>"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#define-camera","title":"Define camera","text":"<ul> <li>position: \\(\\hat{e}\\) (points from the origin to the camera)</li> <li>look-at / gaze direction: \\(\\hat{g}\\) (points from the camera to the object)</li> <li>up direction: \\(\\hat{t}\\)</li> </ul> <p>Usually we transform the camera to the origin, up at Y, look at -Z. And transform the objects along with the camera.</p>"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#transform-the-camera-mv-transformation","title":"Transform the camera (MV transformation)","text":"<p>Steps:</p> <ol> <li>Translate e to origin (\\(T_{view}\\))</li> <li>Rotate g to -Z, t to Y, (g, x, t) to x (\\(R_{view}\\))</li> </ol> <p>\\(T_{view}\\):</p> \\[ T_{view}= \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; -x_e \\\\ 0 &amp; 1 &amp; 0 &amp; -y_e \\\\ 0 &amp; 0 &amp; 1 &amp; -z_e \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>\\(R_{view}\\): Consider its inverse rotation (X to (g, x, t), Y to t, Z to -g).</p> <p>comment</p> <p>Both the direction and order of rotation must be reversed.</p> \\[ R_{view}^{-1}=\\begin{pmatrix} x_{\\hat{g}\\times\\hat{t}} &amp; x_t &amp; x_{-g} &amp; 0 \\\\ y_{\\hat{g}\\times\\hat{t}} &amp; y_t &amp; y_{-g} &amp; 0 \\\\ z_{\\hat{g}\\times\\hat{t}} &amp; z_t &amp; z_{-g} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Since \\(R_{view}\\) is orthoganal, </p> \\[R_{view}=(R_{view}^{-1})^T\\]"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#projection-transformation","title":"Projection transformation","text":"<p>Two 3D -&gt; 2D types:</p> <ol> <li>orthographic projection  </li> <li>perspective projection</li> </ol>"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#orthographic-projection","title":"Orthographic projection","text":"<p>Consider a cuboid \\([l,r]\\times[b,t]\\times[f,n]\\), map it to the canonical cube \\([-1,1]^3\\), and drop Z coordinate to project.</p> Why we just need to drop Z coordinate? <p>In the \"Define camera\" part, we define the camera located at the origin, up at Y, look at -Z.</p> \\[ M_{ortho} = \\begin{pmatrix} \\frac{2}{r - l} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\frac{2}{t - b} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{2}{n - f} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; -\\frac{r + l}{2} \\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{t + b}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{n + f}{2} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\]"},{"location":"GAMES101/Lecture%2004%20Transformations%20Cont/#perspective-projection","title":"Perspective projection","text":"<p>Illustration:</p> <p>{style=\"width:300px\"}</p> <p>Steps: 1. Squish the frustum into a cuboid, all points on the near plane remain unchanged, all points on the far plane undergo in-plane contraction, with the center point of the far plane remaining fixed. 2. Do orthographic projection.</p> \\[ M_{persp\\to ortho}=\\begin{pmatrix} n &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; n &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; n+f &amp; -nf\\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\end{pmatrix} \\] Derivation <p>Squish illustration: {style=\"width:300px\"}  </p> \\[ M_{persp\\to ortho}\\begin{pmatrix}x\\\\y\\\\z\\\\1\\end{pmatrix} =\\begin{pmatrix}nx/z\\\\ny/z\\\\?\\\\1\\end{pmatrix} =\\begin{pmatrix}nx\\\\ny\\\\?\\\\z\\end{pmatrix} \\] <p>thus,</p> \\[ M_{persp\\to ortho}=\\begin{pmatrix} n&amp;0&amp;0&amp;0\\\\ 0&amp;n&amp;0&amp;0\\\\ A&amp;B&amp;C&amp;D\\\\ 0&amp;0&amp;1&amp;0 \\end{pmatrix} \\] <p>According to the properties of squishing, consider a point on the near plane and the middle point on the far plane to solve the third row.</p> <ol> <li>\\((x,y,n,1)\\to(x,y,n,1)=(nx,ny,n^2,n)\\) \\(n^2\\) is unrelated to x and y, thus \\(A=B=0, Cn+D=n^2\\) </li> <li>\\((0,0,f,1)\\to(0,0,f,1)=(0,0,f^2,f)\\) \\(Cf+D=f^2\\)</li> </ol> <p>Solve the equations above:</p> \\[C=n+f, D=-nf\\]"},{"location":"GAMES101/Lecture%2005%20Rasterization%201%20%28Triangles%29/","title":"Lec5 Rasterization 1 (Triangles)","text":"<p>Menu of this lecture</p> <ul> <li>Some basic concepts</li> <li>Rasterization process</li> <li>Different raster displays</li> </ul>"},{"location":"GAMES101/Lecture%2005%20Rasterization%201%20%28Triangles%29/#some-basic-concepts","title":"Some basic concepts","text":"<ol> <li>Aspect radio: width / height</li> <li>Field of view</li> <li>Screen: an array of pixels</li> <li>Resolution: size of the array</li> <li>Rasterize: drawing onto the screen</li> <li>Pixel: (for now, ) a little square with uniform color</li> </ol> <p>\u4e0d\u60f3\u6253\u5b57\u4e86\uff0c\u5f85\u8865\u5145</p>"},{"location":"GAMES101/Lecture%2006%20Rasterization%202%20%28Antiliasing%29/","title":"Lec6 Rasterization 2 (Antiliasing)","text":"<p>Menu of this lecture</p> <ul> <li>Concepts</li> <li>Frequency Domain</li> <li>Filtering</li> <li>Convolution</li> <li>Sampling</li> </ul>"},{"location":"GAMES101/Lecture%2006%20Rasterization%202%20%28Antiliasing%29/#concepts","title":"Concepts","text":"<p>Photograph: sample space Video: sample time</p> <p>Artifact: errors/mistakes/inaccuracies in CG e.g. jaggies, Moire patterns, Wagon wheel effect... Reason: signals are changing too fast, but sampled too slowly.</p> <p>Antialiasing idea: blurring (pre-filtering) before sampleing \u53cd\u8d70\u6837\u7684\u601d\u60f3\uff1a\u5728\u91c7\u6837\u4e4b\u524d\u505a\u6a21\u7cca\uff08\u6ee4\u6ce2\uff09  </p> Antialiasing and Blurred Aliasing <ul> <li>Anitialiasing: filter then sample</li> <li>Blurred Aliasing: sample then filter</li> </ul>"},{"location":"GAMES101/Lecture%2006%20Rasterization%202%20%28Antiliasing%29/#frequency-domain","title":"Frequency Domain","text":"<p>Frequencies: \\(\\cos 2\\pi fx\\), \\(f=\\frac{1}{T}\\) Fourier transform decomposes a signal into frequencies.</p> <p>{style=\"width:600px\"}</p> <p>Why frequency leads to aliasing? Higher frequencies need faster sampling. Otherwise, the reconstruction will be inaccurate. It will appear to be a lower-frequency signal. Two frequencies that are indistinguishable at a given sampling are called \"aliases\".</p>"},{"location":"GAMES101/Lecture%2006%20Rasterization%202%20%28Antiliasing%29/#filtering","title":"Filtering","text":"<p>Filtering(\u6ee4\u6ce2): Getting rid of certain frequency contents.</p> <p>{style=\"width:600px\"}</p> <p>\u5085\u91cc\u53f6\u53d8\u6362\u5c06\u56fe\u50cf\u4ece\u65f6\u57df\u53d8\u4e3a\u9891\u57df\uff0c\u5373\u5c06\u6bcf\u4e2a\u70b9\u7684\u4fe1\u606f\u8f6c\u5316\u4e3a\u4e0d\u540c\u9891\u7387\u7684\u4fe1\u606f\u3002 \u53f3\u8fb9\u56fe\u50cf\uff08\u9891\u8c31\uff09\u7684\u4e2d\u5fc3\u5b9a\u4e49\u4e3a\u4f4e\u9891\u9891\u7387\uff0c\u5468\u56f4\u5b9a\u4e49\u4e3a\u9ad8\u9891\u9891\u7387\uff0c\u4ece\u4e2d\u5fc3\u5230\u5468\u56f4\u9891\u7387\u9012\u589e\u3002\u7528\u56fe\u7247\u7684\u4eae\u5ea6\u8868\u793a\u4e0d\u540c\u9891\u7387\u4e0a\u4fe1\u606f\u7684\u91cf\u3002 \u81ea\u7136\u4e0b\u56fe\u7247\u4fe1\u606f\u57fa\u672c\u51e0\u79cd\u5728\u4f4e\u9891\u533a\u57df\u3002 \u6c34\u5e73\u548c\u7ad6\u76f4\u6709\u9ad8\u4eae\u5ea6\u7684\u5341\u5b57\u7ebf\uff1a\u5085\u91cc\u53f6\u53d8\u6362\u65f6\u8ba4\u4e3a\u56fe\u7247\u5468\u671f\u6027\u91cd\u590d\uff0c\u5230\u8fbe\u4e00\u4e2a\u8fb9\u754c\u540e\u91cd\u590d\u76f8\u5bf9\u8fb9\u754c\u7684\u5185\u5bb9\u3002\u4ea4\u754c\u5904\u56fe\u7247\u5267\u70c8\u53d8\u5316\uff0c\u4ea7\u751f\u6781\u9ad8\u7684\u9ad8\u9891\u4fe1\u53f7\u3002</p> <p>{style=\"width:600px\"}</p> <p>\u9ad8\u901a\u6ee4\u6ce2\uff08High-pass filter\uff09\uff1a\u53bb\u9664\u4f4e\u9891\u9891\u7387\uff0c\u4fdd\u7559\u9ad8\u9891\u9891\u7387\uff0c\u5bf9\u5e94\u4fdd\u7559\u56fe\u50cf\u7684\u8fb9\u754c\u3002 \u4e3a\u4ec0\u4e48\u4fdd\u7559\u8fb9\u754c\uff1f\u8fb9\u754c\u5904\u56fe\u50cf\u53d8\u5316\u5267\u70c8\uff0c\u9ad8\u9891\u4fe1\u53f7\u4fe1\u606f\u5927\u3002</p> <p>{style=\"width:600px\"}</p> <p>\u4f4e\u901a\u6ee4\u6ce2\uff08low-pass filter\uff09\uff1a\u4fdd\u7559\u4f4e\u9891\u9891\u7387\uff0c\u53bb\u9664\u9ad8\u9891\u9891\u7387\uff0c\u5bf9\u5e94\u56fe\u50cf\u53d8\u6a21\u7cca\u3002</p>"},{"location":"GAMES101/Lecture%2006%20Rasterization%202%20%28Antiliasing%29/#convolution","title":"Convolution","text":"<p>Filtering=Convolution=Averaging</p> <p>\u5377\u79ef\uff1a\u5728\u79fb\u52a8\u7a97\u53e3\u65f6\u5c06\u7a97\u53e3\u7684\u6570\u548c\u8986\u76d6\u7684\u4fe1\u53f7\u503c\u70b9\u4e58\uff0c\u5728\u4efb\u610f\u4f4d\u7f6e\u548c\u5468\u56f4\u7684\u6570\u505a\u52a0\u6743\u5e73\u5747\u3002 \u5b9a\u7406\uff1a\u65f6\u57df\u4e0a\u4e24\u4e2a\u4fe1\u53f7\u7684\u5377\u79ef\uff0c\u5bf9\u5e94\u4e8e\u9891\u57df\u4e0a\u4e24\u4e2a\u4fe1\u53f7\u7684\u4e58\u79ef\u3002\u9891\u57df\u4e0a\u4e24\u4e2a\u4fe1\u53f7\u7684\u5377\u79ef\uff0c\u5bf9\u5e94\u4e8e\u65f6\u57df\u4e0a\u4e24\u4e2a\u4fe1\u53f7\u7684\u4e58\u79ef\u3002  </p> <p>\u5377\u79ef\u7684\u65b9\u6cd5\uff1a</p> <ol> <li>\u76f4\u63a5\u5728\u65f6\u57df\u4e0a\u70b9\u4e58</li> <li>\u53d8\u6362\u5230\u9891\u57df\u4e0a\uff0c\u5728\u9891\u57df\u4e0a\u4e58\u79ef\uff0c\u518d\u9006\u53d8\u6362\u4f1a\u65f6\u57df</li> </ol> <p>\u5377\u79ef\u6838\uff1a\u6240\u6709\u7cfb\u6570\u548c\u4e3a1\u3002 \u9891\u8c31\u7684\u4e58\u79ef\u76f8\u5f53\u4e8e\u7559\u4e0b\u5377\u79ef\u6838\u9891\u8c31\u4e2d\u6709\u4fe1\u606f\u7684\u90e8\u5206\u3002 \u5377\u79ef\u6838\u8d8a\u5927\uff0c\u9891\u8c31\u4e0a\u56fe\u50cf\u8d8a\u5c0f\u3002</p>"},{"location":"GAMES101/Lecture%2006%20Rasterization%202%20%28Antiliasing%29/#sampling","title":"Sampling","text":"<p>Sampling=repeating frequency contents</p> <p>\u51b2\u6fc0\u51fd\u6570\uff1a\u6a21\u62df\u5355\u4f4d\u8109\u51b2\uff0c\u53ea\u5728\u4e00\u7cfb\u5217\u5468\u671f\u6027\u7684\u70b9\u4e0a\u6709\u503c\uff0c\u5176\u4f59\u70b9\u4e3a\u96f6\u3002\u51b2\u6fc0\u51fd\u6570\u8f6c\u5316\u5230\u9891\u57df\u540e\u4ecd\u4e3a\u51b2\u6fc0\u51fd\u6570\u3002 \u539f\u4fe1\u53f7\u548c\u51b2\u6fc0\u51fd\u6570\u76f8\u4e58\uff08\u6216\u9891\u57df\u4e0a\u4e24\u4e2a\u4fe1\u53f7\u7684\u5377\u79ef\uff09\uff0c\u5f97\u5230\u91c7\u6837\u540e\u4fe1\u53f7\u3002  </p> <p>\u91c7\u6837\u662f\u91cd\u590d\u539f\u59cb\u4fe1\u53f7\u7684\u9891\u8c31\u3002 \u91c7\u6837\u95f4\u9694\u5f71\u54cd\u539f\u59cb\u4fe1\u53f7\u590d\u5236\u7684\u95f4\u9694\u3002 \u91c7\u6837\u7387\u4e0d\u8db3\uff0c\u91c7\u6837\u95f4\u9694\u5927\uff0c\u539f\u59cb\u4fe1\u53f7\u9891\u8c31\u590d\u5236\u7684\u95f4\u9694\u5c0f\uff0c\u590d\u5236\u642c\u79fb\u65f6\u9891\u8c31\u90e8\u5206\u6df7\u5408\uff0c\u53d1\u751f\u8d70\u6837\u3002</p> <p>\u51cf\u5c0f\u8d70\u6837\u9519\u8bef\uff1a 1. \u63d0\u9ad8\u91c7\u6837\u9891\u7387 2. \u53cd\u8d70\u6837\uff1a\u5148\u53bb\u9664\u9ad8\u9891\u4fe1\u53f7\uff0c\u518d\u91c7\u6837</p> <p>\u53bb\u9664\u9ad8\u9891\u4fe1\u53f7\u540e\uff0c\u6bcf\u4e2a\u5468\u671f\u4e24\u4fa7\u7684\u9891\u7387\u5f3a\u5ea6\u4e3a\u96f6\uff0c\u5728\u7a00\u758f\u91c7\u6837\u642c\u79fb\u95f4\u9694\u5c0f\u7684\u60c5\u51b5\u4e0b\u4e0d\u4ea7\u751f\u91cd\u53e0\u90e8\u5206\u3002</p> <p>Antialiasing by averaging values in pixel area: 1. Convolve f(x,y) by a 1-pixel box-blur 2. Then sample at every pixel's center</p> <p>f(x,y)=inside(triangle,x,y) is equal to the area of the pixel covered by the triangles. </p> <p>\u8ba1\u7b97\u50cf\u7d20\u88ab\u8986\u76d6\u7684\u9762\u79ef\uff1f Multisample Antialiasing(MSAA)\uff1a\u7528\u66f4\u591a\u91c7\u6837\u70b9\u8fdb\u884c\u53cd\u8d70\u6837\u6a21\u7cca\u7684\u8fd1\u4f3c   \u5c06\u50cf\u7d20\u5212\u5206\u4e3a\u66f4\u5c0f\u7684\u50cf\u7d20   MAAA\u89e3\u51b3\u201c\u6a21\u7cca\u201d\u7684\u64cd\u4f5c\uff0c\u6ca1\u6709\u6539\u53d8\u5c4f\u5e55\u7684\u50cf\u7d20\u503c\uff0c\u6ca1\u6709\u63d0\u9ad8\u5206\u8fa8\u7387\u3002  </p> <p>\u5176\u4ed6\u6297\u952f\u9f7f\u7684\u65b9\u6cd5\uff1aFXAA\uff0cTAA \u8d85\u5206\u8fa8\u7387\uff1a\u9632\u6b62\u56fe\u7247\u653e\u5927\u540e\u51fa\u73b0\u952f\u9f7f\uff0cDLSS</p>"},{"location":"GAMES101/Lecture%2007%20Shading%201/","title":"Lec7 Shading 1 (Illumination, Shading and Graphics Pipelines)","text":""},{"location":"GAMES101/Lecture%2007%20Shading%201/#z-buffer","title":"Z-Buffer","text":"<p>Painter's Algorithm: paint from back to front, overwrite in the framebuffer.</p> <p>\u5bf9\u4e09\u89d2\u5f62\u6392\u5e8f\uff0c\u5728\u76f8\u4e92\u906e\u6321\u7684\u60c5\u51b5\u4e0b\u65e0\u6cd5\u6392\u5e8f\u3002\u56e0\u6b64\u5bf9\u50cf\u7d20\u6392\u5e8f\uff08\u6bcf\u4e2a\u50cf\u7d20\u8bb0\u5f55\u6700\u8fd1\u7684\u8ddd\u79bb\uff09\u3002</p> <p>Z-Buffer: store current min. z-value for each sample (pixel). Needs an additional buffer for depth values. Frame buffer stores color values, depth buffer (z-buffer) stores depth. NOTE: For simplicity we suppose z is always positive.</p>"},{"location":"GAMES101/Lecture%2007%20Shading%201/#shading","title":"Shading","text":""},{"location":"GAMES101/Lecture%2007%20Shading%201/#definition","title":"Definition","text":"<p>Shading: The darkening or coloring of an illustration or diagram with parallel lines or a block of color. In this course: The process of applying a material to an object.</p>"},{"location":"GAMES101/Lecture%2007%20Shading%201/#blinn-phong-reflectance-model","title":"Blinn-Phong Reflectance Model","text":"<p>Shading: specular highlight + diffuse reflection + ambient lighting</p> <p>Input:</p> <ol> <li>viewer direction: v</li> <li>surface normal: n</li> <li>light direction: l</li> <li>surface parameters</li> </ol> <p>Diffuse Reflection</p> <p>How much light (energy) is received? Lambert\u2019s cosine law: \\(\\cos\\theta=\\mathbb{i}\\cdot\\mathbb{n}\\)</p> <p>Light Falloff</p> <p>\u70b9\u5149\u6e90\uff0c\u80fd\u91cf\u96c6\u4e2d\u5728\u9760\u8fd1\u4e2d\u5fc3\u7684\u7403\u58f3\uff0c\u4f46\u662f\u8fdc\u8fd1\u7403\u58f3\u80fd\u91cf\u5b88\u6052\u3002 distance: r, intensity: I \u5e73\u65b9\u53cd\u6bd4\uff0c\u8ba1\u7b97\u6709\u591a\u5c11\u5149\u5230\u8fbe shading point</p> <p>**Lambertian (Diffuse) Shading. **</p> \\[L_d=k_d(I/r^2)max(0, \\mathbb{n}\\cdot\\mathbb{l})\\] <p>\\(L_d\\): diffusely reflected light \\(I/r^2\\): energy arrived at the shading point \\(k_d\\): diffuse coefficient \\(max(0, \\mathbb{n}\\cdot\\mathbb{l})\\): energy received by the shading point kd \u5b9a\u4e49\u4e0d\u540c\u6750\u8d28\u5bf9\u5149\u7684\u5438\u6536\uff0ckd \u8d8a\u5927\u7269\u4f53\u8d8a\u4eae</p> <p>\u516c\u5f0f\u4e2d\u4e0d\u542b v\uff1a\u6f2b\u53cd\u5c04\u7684\u53cd\u5c04\u5149\u7ebf\u5747\u5300\u5206\u5e03\u5728\u5404\u4e2a\u65b9\u5411\u4e0a\uff0c\u548c\u89c2\u5bdf\u65b9\u5411\u65e0\u5173\u3002 \u5982\u679c\u533a\u5206 rgb\uff0c\u5219\u7ed9\u4e0d\u540c\u533a\u57df\u8d4b\u4e88\u4e0d\u540c\u989c\u8272\u3002</p>"},{"location":"GAMES101/Lecture%2008%20Shading%202/","title":"Lec8 Shading 2 (Shading, Pipeline and Texture Mapping)","text":""},{"location":"GAMES101/Lecture%2008%20Shading%202/#specular-term","title":"Specular Term","text":"<p>\u4ec0\u4e48\u65f6\u5019\u80fd\u770b\u5230\u9ad8\u5149\uff1f</p> <ol> <li>\u7269\u4f53\u5149\u6ed1\uff0c\u53cd\u5c04\u96c6\u4e2d\u5728\u955c\u9762\u53cd\u5c04</li> <li>\u89c6\u89d2\u4e0e\u955c\u9762\u53cd\u5c04\u65b9\u5411\u63a5\u8fd1</li> </ol> <p>\u534a\u7a0b\u5411\u91cf\uff1a\u5149\u7167\u65b9\u5411\u548c\u89c2\u5bdf\u65b9\u5411\u7684\u89d2\u5e73\u5206\u7ebf\uff0c\u7528\u4e8e\u5224\u65ad\u89c2\u5bdf\u65b9\u5411\u548c\u955c\u9762\u53cd\u5c04\u65b9\u5411\u63a5\u8fd1\u7684\u7a0b\u5ea6</p> <p>\u4e3a\u4ec0\u4e48\u7528\u534a\u7a0b\u5411\u91cf\u800c\u4e0d\u662f\u76f4\u63a5\u8ba1\u7b97\uff1f</p> <p>\u534a\u7a0b\u5411\u91cf\u53ea\u9700\u8981 v \u548c l\uff0c\u8ba1\u7b97\u7b80\u5355</p> \\[\\mathbb{h}=bisector(\\mathbb{v},\\ mathbb{l})=\\frac{\\mathbb{v}+\\mathbb{l}}{|| \\mathbb{v}+\\mathbb{l} ||}\\] <p>\u9ad8\u5149\u7684 Bliinn-Phone \u516c\u5f0f\uff1a</p> \\[L_s=k_s(I/r^2)max(0, \\mathbb{n}\\cdot\\mathbb{h})^P\\] <p>cosine power plots: increasing p narrows the reflection lobe</p> <p>{style=\"width:500px\"}</p> <p>Influence of k and p:</p> <p>{style=\"width:500px\"}</p>"},{"location":"GAMES101/Lecture%2008%20Shading%202/#ambient-term","title":"Ambient Term","text":"<p>\u73af\u5883\u5149\uff1a\u8ba4\u4e3a\u73af\u5883\u5149\u5f3a\u5ea6\u5904\u5904\u76f8\u540c</p> \\[L_a=k_aI_a\\] <p>\\(L_a\\): reflected ambient lignt \\(k_a\\): ambient coefficient This is approximate / fake</p> <p>\u4e09\u9879\u76f8\u52a0\uff1a</p> \\[L=L_a+L_d+L_s\\] <p>{style=\"width:500px\"}</p>"},{"location":"GAMES101/Lecture%2008%20Shading%202/#shading-frequency","title":"Shading Frequency","text":"<ol> <li>\u786e\u5b9a shading point \u65f6\uff0c\u5bf9\u4e00\u4e2a\u5e73\u9762\u8fdb\u884c\u76f8\u540c\u64cd\u4f5c</li> <li>\u5bf9\u6bcf\u4e2a\u9876\u70b9\u8ba1\u7b97\u6cd5\u7ebf\u5e76\u7740\u8272\uff0c\u4e2d\u95f4\u7684\u70b9\u7528\u5e73\u6ed1\u63d2\u503c</li> <li>\u5bf9\u6bcf\u4e2a\u50cf\u7d20\u5e94\u7528\u7740\u8272</li> <li>Flat shading: triangle face is flat (one normal vector) ,but is not good for smooth surfaces</li> <li>Gouraud shading: Interpolate colors from vertices across triangles, each vertex has a normal vector</li> <li>Phong shading: Interpolate colors from vertices across each triangle, compute full shading model at each pixel (Not the Blinn-Phong Reflectance Model)</li> </ol> <p>Shading frequency: face-&gt;vertex-&gt;pixel</p> <p>\u9876\u70b9\u7684\u6cd5\u7ebf\u600e\u4e48\u8ba1\u7b97\uff1f \u5468\u56f4\u6240\u6709\u4e09\u89d2\u5f62\u7684\u6cd5\u7ebf\u7684\u5e73\u5747</p> \\[N_v=\\frac{\\sum_iN_i}{||\\sum_iN_i||}\\] <p>\u6216\u8005\u518d\u6839\u636e\u4e09\u89d2\u5f62\u9762\u79ef\u52a0\u6743</p> <p>\u50cf\u7d20\u6cd5\u7ebf\u600e\u4e48\u8ba1\u7b97\uff1f</p> <p>\u6839\u636e\u9876\u70b9\u6cd5\u7ebf\u548c\u91cd\u5fc3\uff0c\u8ba1\u7b97\u5404\u4e2a\u70b9\u7684\u6cd5\u7ebf\uff0c\u518d\u5f52\u4e00\u5316</p>"},{"location":"GAMES101/Lecture%2008%20Shading%202/#graphics-pipeline","title":"Graphics Pipeline","text":"<p>Graphics Pipeline (Real-time Rendering Pipeline) \u56fe\u5f62\u7ba1\u7ebf\uff08\u5b9e\u65f6\u6e32\u67d3\u7ba1\u7ebf\uff09</p> <p>Shader(\u50cf\u7d20\u7740\u8272\u5668)\uff1a\u8ba1\u7b97\u6bcf\u4e00\u4e2a\u50cf\u7d20\u6700\u540e\u7684\u989c\u8272\uff0c\u5e76\u8f93\u51fa\u3002\u53ef\u4ee5\u6307\u5b9a\u6bcf\u4e00\u4e2a\u50cf\u7d20\u7684\u7740\u8272</p> <p>GLSL</p>"},{"location":"GAMES101/Lecture%2008%20Shading%202/#texture-mapping","title":"Texture Mapping","text":"<p>\u5728\u7269\u4f53\u7684\u4e0d\u540c\u4f4d\u7f6e\u5b9a\u4e49\u4e0d\u540c\u7684\u5c5e\u6027\uff08\u5438\u6536\u5149\u4e0d\u540c\uff0c\u4ea7\u751f\u4e0d\u540c\u989c\u8272\uff09</p> <p>\u5b9a\u4e49\u5728\u7269\u4f53\u8868\u9762\uff1a Surface lives in 3D world space. Every 3D surface point alsohas a place where it goes in the 2D image. \u5373\u4e09\u7ef4\u7684\u7269\u4f53\u8868\u9762\u53ef\u4ee5\u4e0e\u4e00\u5f20\u4e8c\u7ef4\u7684\u56fe\u4e00\u4e00\u5bf9\u5e94\uff0c\u8fd9\u5f20\u4e8c\u7ef4\u7684\u56fe\u5c31\u662f\u7eb9\u7406\u3002</p> <p>Parameterizarion\uff08\u53c2\u6570\u5316\uff09\uff1a\u5c06\u4e09\u7ef4\u7269\u4f53\u8868\u9762\u7684\u6240\u6709\u4e09\u89d2\u5f62\u6620\u5c04\u5230\u4e8c\u7ef4\uff0c\u4e14\u4e09\u89d2\u5f62\u5c3d\u53ef\u80fd\u5c11\u626d\u66f2\uff08\u4fdd\u6301\u5927\u5c0f\u5173\u7cfb\uff09\uff0c\u4e14\u5c3d\u53ef\u80fd\u4ecd\u6784\u6210\u5b8c\u6574\u7684\u56fe\u5f62\u3002</p> <p>Texture can be used multiple times. \u91cd\u590d\u4f7f\u7528\u7eb9\u7406\uff1aTile</p> <p>\u5df2\u77e5\u4e09\u89d2\u5f62\u9876\u70b9\u5750\u6807\uff0c\u600e\u4e48\u5f97\u5230\u4e09\u89d2\u5f62\u5185\u90e8\u67d0\u4e2a\u70b9\u7684\u5750\u6807\uff1f Barycentric Coordinates (\u4e0b\u4e00\u8bb2)</p>"},{"location":"GAMES101/Lecture%2009%20Shading%203/","title":"Lec9 Shading 3 (Texture Mapping cont.)","text":"<ul> <li>Barycentric Coordinates</li> <li>Texture queries</li> <li>Application of textures</li> </ul> <p>Barycentric Coordinates: \u4e09\u89d2\u5f62\u4e2d\u4efb\u4f55\u4e00\u70b9\u90fd\u53ef\u8868\u793a\u4e3a\u4e09\u4e2a\u9876\u70b9\u5750\u6807\u7684\u7ebf\u6027\u7ec4\u5408</p> <p>A coordinate system for triangle \\((\\alpha, \\beta,\\gamma)\\):</p> \\[(x,y)=\\alpha A+\\beta B+\\gamma C\\] <p>\u5176\u4e2d\\(\\alpha+\\beta+\\gamma=1\\)\uff0c\u4e14\u90fd\u662f\u975e\u8d1f\u7684 \u6ee1\u8db3\u8fd9\u4e09\u4e2a\u6761\u4ef6\u5219\u70b9\u5728\u4e09\u89d2\u5f62\u5185\uff0c\u662f\u91cd\u5fc3\u5750\u6807</p> <p>\u600e\u4e48\u6c42\u91cd\u5fc3\u5750\u6807\uff1f \u5954\u9a70\u5b9a\u7406\uff1a\u7528\u9762\u79ef\u6c42\u91cd\u5fc3\u5750\u6807 \\(A_A\\)\u8868\u793a A \u76f8\u5bf9\u7684\u5c0f\u4e09\u89d2\u5f62\u7684\u9762\u79ef</p> \\[\\alpha=\\frac{A_A}{A_A+A_B+A_C}\\] <p>\u6216\uff1a\u57fa\u4e8e\u70b9\u5750\u6807\u7684\u516c\u5f0f\u3002\u63a8\u5bfc\u53ef\u53c2\u8003\u6e32\u67d3\u5668 Tinyrenderer \u5185\u5bb9\u3002</p> <p>{style=\"width:500px\"}</p> <p>Linearly interpolate values at vertices:</p> \\[V=\\alpha V_A+\\beta V_B+\\gamma V_C\\] <p>\u95ee\u9898\uff1a\u6295\u5f71\u4e0d\u80fd\u4fdd\u8bc1\u91cd\u5fc3\u5750\u6807\u4e0d\u53d8 \u89e3\u51b3\uff1a\u53d6\u4e09\u7ef4\u5750\u6807\u8ba1\u7b97\uff0c\u8fd0\u7b97\u540e\u518d\u6295\u5f71\u5230\u4e8c\u7ef4\u5e73\u9762</p>"},{"location":"GAMES101/Lecture%2009%20Shading%203/#applying-texture","title":"Applying texture","text":"<p>for each rasterized screen sample (x,y):</p> <ol> <li>(u,v) = evaluate texture coordinate at (x,y)</li> <li>texcolor = texture.sample(u,v)</li> <li>set sample\u2019s color to texcolor</li> </ol> <p>\u7eb9\u7406\u5206\u8fa8\u7387\u4f4e\u4e8e\u56fe\u7247\u5206\u8fa8\u7387? \u9700\u8981\u7eb9\u7406\u653e\u5927 \uff08A pixel on a texture: texel\uff09</p> <ol> <li>\u975e\u6574\u6570\u7684\u5750\u6807 round \u6210\u6574\u6570</li> <li>\u53cc\u7ebf\u6027\u63d2\u503c\uff1a\u627e\u76f8\u90bb\u7684\u56db\u4e2a\u50cf\u7d20\uff0c\u548c\u5de6\u4e0b\u89d2\u7684\u6c34\u5e73\u7ad6\u76f4\u65b9\u5411\u8ddd\u79bb\u4e3a s \u548c t\uff0c\u7ebf\u6027\u63d2\u503c\uff08\u5148\u6c34\u5e73\u5f97\u5230\u4e24\u4e2a\u4e2d\u95f4\u70b9\uff0c\u518d\u5bf9\u7ad6\u76f4\u4e2d\u95f4\u70b9\u63d2\u503c\uff09</li> <li>Bicubic\uff1a\u53d6\u5468\u56f4 16 \u4e2a</li> </ol> <p>\u7eb9\u7406\u56fe\u7247\u592a\u5927\uff1f \u50cf\u7d20\u5728\u7eb9\u7406\u4e0a\u8986\u76d6\u5f88\u5927\u4e00\u7247\u533a\u57df \u7f51\u683c\u5e73\u9762\u900f\u89c6\uff1a\u8fd1\u5904\u952f\u9f7f\uff0c\u8fdc\u5904\u6469\u5c14\u7eb9</p> <ol> <li>\u8d85\u91c7\u6837\uff1a\u5728\u4e00\u4e2a\u50cf\u7d20\u5185\u90e8\u6709\u591a\u4e2a\u91c7\u6837\u70b9\u5e73\u5747</li> <li>\u8303\u56f4\u67e5\u8be2\u6c42\u5e73\u5747\u503c\uff1a\u53d6\u50cf\u7d20\u8986\u76d6\u7684\u4e00\u7247\u533a\u57df\u7684\u5e73\u5747\u503c</li> </ol>"},{"location":"GAMES101/Lecture%2009%20Shading%203/#mipmap","title":"Mipmap","text":"<p>mipmap: Allowing (fast, approx., square) range queries \u7ed9\u5b9a\u4e00\u5757\u6b63\u65b9\u5f62\u533a\u57df\uff0c\u5feb\u901f\u67e5\u8be2\u5230\u8986\u76d6\u7684\u50cf\u7d20\u7684 rgb \u5e73\u5747\u503c\u3002</p> <p>1. \u751f\u6210\uff1a</p> <p>\u6bcf\u6b21\u5c06\u957f\u3001\u5bbd\u7684\u5206\u8fa8\u7387\u90fd\u51cf\u534a\uff0c\u76f4\u5230\u51cf\u4e3a 1*1\uff0c\u751f\u6210\u4e00\u7cfb\u5217 mipmap(mip hierarchy)\u3002 \u6bcf\u6b21\u7684\u5b58\u50a8\u7a7a\u95f4\u662f\u4e0a\u4e00\u6b21\u7684 1/4\uff0c\u989d\u5916\u5f15\u5165\u7684\u5b58\u50a8\u91cf\u4e3a\u539f\u56fe\u7684 1/3\u3002</p> <p>2. \u67e5\u8be2\uff1a</p> <p>\u5bf9\u4efb\u610f\u50cf\u7d20\uff0c\u5047\u8bbe\u5728\u539f\u56fe\u4e2d\u5411\u4e0a\u3001\u5411\u53f3\u79fb\u52a8 1 \u4e2a\u50cf\u7d20\u65f6\uff0c\u5728\u7eb9\u7406\u56fe\u4e2d\u79fb\u52a8\u8ddd\u79bb\u662f<code>l1</code>\u3001<code>l2</code>\u3002 \u4ee4\u50cf\u7d20\u5728\u7eb9\u7406\u56fe\u4e0a\u8986\u76d6\u7684\u533a\u57df\u4e3a\u6b63\u65b9\u5f62\uff0c\u8fb9\u957f\u4e3a<code>max(l1,l2)</code>\u3002 \u7528 mipmap \u67e5\u8be2\u8fd9\u4e2a\u6b63\u65b9\u5f62\u8986\u76d6\u7684\u50cf\u7d20\u7684 rgb \u5e73\u5747\u503c\u3002</p> <p>\u8ddd\u79bb\u8fd1\u65f6\uff0c\u4e00\u4e2a\u50cf\u7d20\u8986\u76d6\u7684\u533a\u57df\u5c0f\uff0c\u5728\u4f4e\u5c42\u7684 mipmap\uff08\u63a5\u8fd1\u539f\u56fe\uff09\u4e0a\u67e5\u8be2\uff1b \u8ddd\u79bb\u8fdc\u65f6\uff0c\u4e00\u4e2a\u50cf\u7d20\u8986\u76d6\u7684\u533a\u57df\u5927\uff0c\u5728\u9ad8\u5c42\u7684 mipmap\uff08\u5206\u8fa8\u7387\u4f4e\uff09\u4e0a\u67e5\u8be2\u3002</p> <p>\u53d8\u5316\u4e0d\u8fde\u7eed\uff1f</p> <p>Trilinear Interpolation: \u5148\u5728\u76f8\u90bb\u7684\u4e24\u4e2a mipmap \u4e0a\u5173\u4e8e\u884c\u3001\u5217\u8fdb\u884c bilinear interpolation\uff0c\u518d\u5728\u4e24\u4e2a\u5c42\u4e4b\u95f4\u7ebf\u6027\u63d2\u503c\u3002</p> <p>\u7f3a\u70b9\uff1aOverblur\uff0c\u8fdc\u5904\u62b9\u53bb\u7ec6\u8282 \u90e8\u5206\u56e0\u4e3a mipmap \u53ea\u652f\u6301\u6b63\u65b9\u5f62\u67e5\u8be2\uff0c\u975e\u6b63\u65b9\u5f62\u8bef\u5dee\u5927 \u89e3\u51b3\uff1aAnisotropic Filtering</p>"},{"location":"GAMES101/Lecture%2009%20Shading%203/#anisotropic-filtering","title":"Anisotropic Filtering","text":"<p>\u6bcf\u6b21\u53d8\u6362\u4ec5\u957f\u6216\u5bbd\u51cf\u5c0f\u4e00\u534a\uff0c\u4fdd\u7559\u751f\u6210\u7684\u6240\u6709\u56fe\uff08\u4e0d\u4e00\u5b9a\u662f\u6b63\u65b9\u5f62\uff09\u3002 \u989d\u5916\u5f00\u9500\u662f\u539f\u56fe\u7684 3 \u500d\u3002</p> <p>{style=\"width:400px\"}</p> <p>\u4e3a\u4ec0\u4e48\uff1f \u539f\u56fe\u4e2d\u4e00\u4e2a\u50cf\u7d20\u6620\u5c04\u5230\u7eb9\u7406\u4e0a\u4e0d\u4e00\u5b9a\u662f\u6b63\u65b9\u5f62\uff0c\u5373\u539f\u56fe\u4e2d\u6c34\u5e73\u3001\u7ad6\u76f4\u65b9\u5411\u79fb\u52a8 1 \u4e2a\u50cf\u7d20\uff0c\u7eb9\u7406\u56fe\u4e2d\u79fb\u52a8\u8ddd\u79bb\u53ef\u80fd\u4e0d\u540c\u3002</p> <p>Can look up axis-aligned rectangular zones.</p> <p>But diagonal footprint still a problem.</p>"},{"location":"GAMES101/Lecture%2009%20Shading%203/#ewa-filtering","title":"EWA Filtering","text":"<p>Use multiple lookups, weighted average.</p> <p>\u5bf9\u4e8e\u4e0d\u89c4\u5219\u5f62\u72b6\uff0c\u5c06\u56fe\u5f62\u5206\u5272\u6210\u4e0d\u540c\u4e2a\u5706\u5f62\uff0c\u591a\u6b21\u67e5\u8be2\u5706\u5f62\u3002</p>"},{"location":"GAMES101/Lecture%2010%20Geometry%201/","title":"Lec10 Geomertry 1 (Introduction)","text":""},{"location":"GAMES101/Lecture%2010%20Geometry%201/#application-of-texture","title":"Application of Texture","text":""},{"location":"GAMES101/Lecture%2010%20Geometry%201/#environmental-lighting","title":"Environmental Lighting","text":"<p>Environment map used to render realistic lighting.</p> <p>Spherical Environment Map: Store the environment map in the surface of a sphere. \u7f3a\u70b9\uff1a\u9760\u8fd1\u9876\u90e8\u548c\u5e95\u90e8\u7684\u56fe\u50cf\u626d\u66f2</p> <p>Cube Map: A vector maps to cube point along that direction. The cube is textured with 6 square texture maps. \u4f18\u70b9\uff1a\u626d\u66f2\u5c11 \u7f3a\u70b9\uff1a\u7ed9\u5b9a\u65b9\u5411\uff0c\u8981\u5148\u5224\u65ad\u8fd9\u4e2a\u65b9\u5411\u7684\u5149\u7167\u4fe1\u606f\u8bb0\u5f55\u5728\u54ea\u4e2a\u9762\u4e0a</p>"},{"location":"GAMES101/Lecture%2010%20Geometry%201/#bump-mapping","title":"Bump Mapping","text":"<p>Adding surface detail without adding more triangles. \u7528\u7eb9\u7406\u8d34\u56fe\u5b9a\u4e49\u7269\u4f53\u8868\u9762\u4e0a\u6bcf\u4e2a\u70b9\u7684\u76f8\u5bf9\u9ad8\u5ea6/\u6cd5\u7ebf, Perturb surface normal per pixel.</p> <p>\u600e\u4e48\u6270\u52a8\u6cd5\u7ebf\uff1f\uff08\u4ee5 flatland \u4e3a\u4f8b\uff09 \u4e8c\u7ef4\uff1a\u5b9a\u4e49\u6270\u52a8\u540e\u7684\u51fd\u6570\uff0c\u7528\u5dee\u5206\u6c42\u5207\u7ebf\uff0c\u4e0e\u5207\u7ebf\u5782\u76f4\u7684\u65b9\u5411\u4e3a\u6cd5\u7ebf\u3002 \u4e09\u7ef4\uff1a u\u3001v \u65b9\u5411\u7684\u5dee\u5206\u5206\u522b\u4e3a dp/du\u3001dp/dv\uff0c\u5219\u6cd5\u7ebf\u4e3a(-dp/du, -dp/dv, 1)\u3002</p> <p>Displacement mapping: \u51f9\u51f8\u8d34\u56fe\u53ea\u901a\u8fc7\u8d34\u56fe\u4fe1\u606f\u6539\u53d8\u6cd5\u7ebf\uff0c\u6ca1\u6709\u6539\u53d8\u70b9\u7684\u5b9e\u9645\u4f4d\u7f6e\uff0c\u5728\u8fb9\u7f18\u5904\u548c\u9634\u5f71\u5904\u4e0d\u4f1a\u968f\u51f9\u51f8\u4f4d\u79fb\u53d8\u5316\u3002 \u800c\u4f4d\u79fb\u8d34\u56fe\u6539\u53d8\u70b9\u7684\u5b9e\u9645\u4f4d\u7f6e\uff0c\u66f4\u771f\u5b9e\u3002</p> <p>\u4f4d\u79fb\u8d34\u56fe\u7684\u4ee3\u4ef7\uff1a\u8981\u6c42\u4e09\u89d2\u5f62\u672c\u8eab\u5212\u5206\u5f97\u8db3\u591f\u7ec6\uff0c\u4e09\u89d2\u5f62\u9876\u70b9\u95f4\u7684\u95f4\u9694\u5927\u4e8e\u7eb9\u7406\u70b9\u7684\u95f4\u9694</p> <p>\u52a8\u6001\u533a\u95f4\u7ec6\u5206\uff1a\u68c0\u6d4b\u662f\u5426\u9700\u8981\u5c06\u4e09\u89d2\u5f62\u7ec6\u5206</p>"},{"location":"GAMES101/Lecture%2010%20Geometry%201/#3d-texture","title":"3D Texture","text":"<p>3D procedual noise + solid modeling</p> <p>Can be used in volumn rendering.</p>"},{"location":"GAMES101/Lecture%2010%20Geometry%201/#examples-of-geometry","title":"Examples of Geometry","text":"<ul> <li>Implicit: algebaraic surface, level sets, distance functions...</li> <li>Explicit: point cloud, polygon mesh, subdivision...</li> </ul> <p>Implicit:\u4e0d\u7ed9\u51fa\u70b9\u7684\u5177\u4f53\u5750\u6807\uff0c\u800c\u662f\u63cf\u8ff0\u54ea\u4e9b\u70b9\u5728\u4e00\u4e2a\u9762\u4e0a e.g. \\(x^2+y^2+z^2=1\\). More generally, f(z,y,z)=0 \u4f18\u70b9\uff1a\u5224\u5b9a\u7ed9\u5b9a\u70b9\u662f\u5426\u5728\u9762\u4e0a\u7b80\u5355 \u7f3a\u70b9\uff1a\u786e\u5b9a\u56fe\u5f62\u56f0\u96be</p> <p>Explicit:\u76f4\u63a5\u7ed9\u51fa\u70b9\u7684\u5750\u6807\uff0c\u6216\u901a\u8fc7\u53c2\u6570\u6620\u5c04\u5f97\u5230 e.g. \\(f:\\mathbb{R}\\to\\mathbb{R}; (u,v)\\mapsto(x,y,z)\\) \u4f18\u70b9\uff1a\u786e\u5b9a\u56fe\u5f62\u7b80\u5355 \u7f3a\u70b9\uff1a\u5224\u5b9a\u7ed9\u5b9a\u70b9\u662f\u5426\u5728\u9762\u4e0a\u56f0\u96be</p>"},{"location":"GAMES101/Lecture%2010%20Geometry%201/#more-implicit-representation","title":"More Implicit Representation","text":"<ol> <li>Algebriac Surface: \u7528\u6570\u5b66\u516c\u5f0f\u8868\u793a\u9762\u3002</li> <li>Constructed Solid Geometry (CSG): \u901a\u8fc7\u57fa\u672c\u51e0\u4f55\u5f62\u4f53\u7684\u5e03\u5c14\u8fd0\u7b97\uff0c\u5f97\u5230\u590d\u6742\u51e0\u4f55\u5f62\u4f53\u3002</li> <li>Distance Function: \u5b9a\u4e49\u7a7a\u95f4\u4e2d\u4efb\u4f55\u4e00\u70b9\u5230\u8868\u9762\u7684\u6700\u5c0f\u8ddd\u79bb\uff08\u8ddd\u79bb\u51fd\u6570\uff0c\u53ef\u6b63\u53ef\u8d1f\uff09\uff0c\u8ddd\u79bb\u51fd\u6570\u4e3a 0 \u7684\u4f4d\u7f6e\u4e3a\u8868\u9762\u3002\u53ef\u7528\u4e8e\u56fe\u5f62\u7684\u878d\u5408\u3002</li> <li>Level Set Methods: \u5c06\u8ddd\u79bb\u51fd\u6570\u6309\u683c\u5b58\u50a8\uff0c\u7528\u7ebf\u6027\u63d2\u503c\u5f97\u5230\u8ddd\u79bb\u4e3a 0 \u7684\u70b9\u3002</li> <li>Fractals: \u5206\u5f62\u3002</li> </ol> <p>Pros:</p> <ul> <li>compact description</li> <li>certain queries easy</li> <li>good for ray-to-surface intersection</li> <li>for simple shapes, exact description / no sampling error</li> <li>easy to handle changes in topology</li> </ul>"},{"location":"GAMES101/Lecture%2011%20Geometry%202/","title":"Lec11 Geomertry 2 (Curves and Surfaces)","text":""},{"location":"GAMES101/Lecture%2011%20Geometry%202/#explicit-representations","title":"Explicit Representations","text":"<p>1. Point Cloud list of points (x,y,z) \u76f4\u63a5\u626b\u63cf\u5f97\u5230\u70b9\u4e91\uff0c\u9700\u8981\u901a\u8fc7\u7b97\u6cd5\u8f6c\u5316\u4e3a\u4e09\u89d2\u5f62\u9762 \u5982\u679c\u70b9\u4e91\u5bc6\u5ea6\u8fc7\u4f4e\uff0c\u5219\u4e0d\u80fd\u753b\u51fa\u56fe\u50cf</p> <p>2. Polygon Mesh \u4e09\u89d2\u5f62\u9762\u8868\u793a Wavefront Object File (.obj) Format: v \u8868\u793a\u70b9\u7684\u5750\u6807\uff0cvn \u8868\u793a\u6cd5\u7ebf\uff0cvt \u8868\u793a\u7eb9\u7406\u5750\u6807\uff0cf \u8868\u793a\u9762\u7684\u9876\u70b9\u7684\u7f16\u53f7</p>"},{"location":"GAMES101/Lecture%2011%20Geometry%202/#curves","title":"Curves","text":""},{"location":"GAMES101/Lecture%2011%20Geometry%202/#bezier-curves","title":"Bezier Curves","text":"<p>\u8d1d\u585e\u5c14\u66f2\u7ebf\uff1a\u7528\u4e00\u7cfb\u5217\u63a7\u5236\u70b9\u5b9a\u4e49\u66f2\u7ebf</p> <p>e.g.\u6ee1\u8db3\u6761\u4ef6\uff1a</p> <ol> <li>\u4ece P0 \u5f00\u59cb\uff0c\u4e14\u5207\u7ebf\u65b9\u5411\u4e3a P0P1</li> <li>\u4ece P3 \u7ed3\u675f\uff0c\u4e14\u5207\u7ebf\u65b9\u5411\u4e3a P2P3</li> </ol> <p>{style=\"width:250px\"}</p>"},{"location":"GAMES101/Lecture%2011%20Geometry%202/#de-casteljiau-algorithm","title":"de Casteljiau Algorithm","text":"<p>Consider three points (quadratic Bezier):</p> <p>\u5c06\u8d77\u70b9\u5230\u7ec8\u70b9\u89c6\u4e3a 0~1\uff0c\u5bf9\u5176\u4e2d\u4efb\u4e00\u4e2a\u6bd4\u4f8b\u4e3a t \u7684\u70b9\uff0c\u6309\u4e0b\u56fe\u65b9\u6cd5\u786e\u5b9a\uff1a</p> <p>{style=\"width:600px\"}</p> <p>\u56db\u70b9\uff1a</p> <p>{style=\"width:250px\"}</p> <p>Bernstein form of a Bezier curve of order n:</p> \\[b^n(t)=\\sum_{j=0}^nb_jB_j^n(t)\\] <p>Bernstein polynomials:</p> \\[B_i^n(t)=\\begin{pmatrix}n \\\\ i\\end{pmatrix}t^i (1-t)^{n-i}\\] <p>e.g.</p> <p>2D:</p> \\[b^2(t)=b_0(1-t)^2+b_1 2t(1-t)+b_2 t^2\\] <p>3D:</p> \\[b^3(t)=b_0 (1-t)^3+b_1 3t(1-t)^2+b_2 3t^2(1-t)+b_3 t^3\\]"},{"location":"GAMES101/Lecture%2011%20Geometry%202/#properties-of-bezier-curves","title":"Properties of Bezier Curves","text":"<ol> <li> <p>Affine transformation property: transform curve by transforming control points.    \u5728\u4eff\u5c04\u53d8\u6362\u4e0b\uff0c\u53d8\u6362\u63a7\u5236\u70b9\u518d\u7528\u53d8\u6362\u540e\u7684\u70b9\u753b\u66f2\u7ebf\uff0c\u548c\u76f4\u63a5\u5bf9\u66f2\u7ebf\u4e0a\u70b9\u53d8\u6362\uff0c\u4e24\u8005\u7ed3\u679c\u76f8\u540c\u3002    \u4f46\u4ec5\u5bf9\u4eff\u5c04\u53d8\u6362\u6210\u7acb\uff0c\u6295\u5f71\u7b49\u53d8\u6362\u4e0d\u6210\u7acb\u3002</p> </li> <li> <p>Convec hull property: curve is within convex hull of control points.    \u7ed8\u5236\u7684\u8d1d\u585e\u5c14\u66f2\u7ebf\u4e00\u5b9a\u5728\u6240\u6709\u63a7\u5236\u70b9\u5f62\u6210\u7684\u51f8\u5305\u5185\u3002    e.g. \u82e5\u63a7\u5236\u70b9\u5171\u7ebf\uff0c\u5219\u8d1d\u585e\u5c14\u66f2\u7ebf\u662f\u8fd9\u6761\u7ebf\u672c\u8eab</p> </li> </ol>"},{"location":"GAMES101/Lecture%2011%20Geometry%202/#piecewise-bezier-curves","title":"Piecewise Bezier Curves","text":"<p>\u7528\u591a\u4e2a\u63a7\u5236\u70b9\u540c\u65f6\u63a7\u5236\u4e00\u6761\u66f2\u7ebf\uff0c\u4e2d\u95f4\u90e8\u5206\u4e0d\u80fd\u53cd\u6620\u8d8b\u52bf\u3002\u7528\u591a\u7ec4\u70b9\u9010\u6bb5\u63a7\u5236\uff0c\u4e00\u822c\u6bcf\u56db\u4e2a\u70b9\u63a7\u5236\u4e00\u6bb5\uff0c\u518d\u5c06\u6240\u6709\u66f2\u7ebf\u8fde\u63a5\u3002</p> <p>\u82e5\u63a7\u5236\u6746\u548c\u4e2d\u95f4\u70b9\u5171\u7ebf\uff0c\u4e14\u63a7=\u63a7\u5236\u6746\u5927\u5c0f\u76f8\u540c\uff0c\u5219\u8ba4\u4e3a\u8fde\u63a5\u70b9\u5904\u66f2\u7ebf\u8fde\u7eed\u3002</p> <p>Continuity:</p> <p>\\(C^0\\) continuity: \\(a_n=b_n\\)\uff0c\u51e0\u4f55\u4e0a\u4e0d\u95f4\u65ad</p> <p>\\(C^1\\) continuity: \\(a_n=b_0=\\frac{1}{2}(a_{n-1}+b_1)\\)\uff0c\u524d\u540e\u63a7\u5236\u6746\u957f\u5ea6\u76f8\u540c\uff0c\u5207\u7ebf\u8fde\u7eed</p>"},{"location":"GAMES101/Lecture%2011%20Geometry%202/#other-types-of-splines","title":"Other Types of Splines","text":"<p>Spline\uff08\u6837\u6761\uff09\uff1a\u7531\u4e00\u7cfb\u5217\u63a7\u5236\u70b9\u63a7\u5236\u7684\u66f2\u7ebf\uff0c\u6ee1\u8db3\u7279\u5b9a\u7684\u8fde\u7eed\u6027</p> <p>B-Spline\uff08\u57fa\u6837\u6761\uff09: \u5bf9\u8d1d\u585e\u5c14\u66f2\u7ebf\u7684\u589e\u5f3a\uff0c\u589e\u52a0\u4e86\u5c40\u90e8\u6027\uff0c\u6539\u52a8\u4e00\u4e2a\u70b9\u5f71\u54cd\u66f2\u7ebf\u7684\u4e00\u4e2a\u8303\u56f4\u5185\u800c\u4e0d\u662f\u5f71\u54cd\u6574\u4e2a\u66f2\u7ebf</p>"},{"location":"GAMES101/Lecture%2011%20Geometry%202/#surfaces","title":"Surfaces","text":""},{"location":"GAMES101/Lecture%2011%20Geometry%202/#bezier-surfaces","title":"Bezier Surfaces","text":"<ol> <li>\u6cbf x \u65b9\u5411\u7684\u63a7\u5236\u70b9\uff0c\u7ed8\u5236\u6cbf x \u65b9\u5411\u7684\u8d1d\u585e\u5c14\u66f2\u7ebf\uff1b</li> <li>\u5728\u4e0a\u8ff0\u66f2\u7ebf\u6cbf y \u65b9\u5411\u53d6\u70b9\u4f5c\u4e3a\u63a7\u5236\u70b9\uff0c\u7ed8\u5236\u6cbf y \u65b9\u5411\u7684\u8d1d\u585e\u5c14\u66f2\u7ebf\uff1b</li> <li>y \u65b9\u5411\u66f2\u7ebf\u626b\u8fc7\u7684\u9762\u4e3a\u8d1d\u585e\u5c14\u66f2\u9762</li> </ol>"},{"location":"GAMES101/Lecture%2011%20Geometry%202/#mesh-operations","title":"Mesh Operations","text":"<ul> <li>Mesh subdivision  </li> <li>Mesh simplification  </li> <li>Mesh regularization  </li> </ul>"},{"location":"GAMES101/Lecture%2012%20Geometry%203/","title":"Lec12 Geometry 3","text":""},{"location":"GAMES101/Lecture%2012%20Geometry%203/#mesh-operation","title":"Mesh Operation","text":"<ul> <li>Mesh Subdivision\uff1a\u7c7b\u4f3c\u589e\u5927\u5206\u8fa8\u7387\uff0c\u5c55\u793a\u66f4\u591a\u7ec6\u8282\u3002</li> <li>Mesh Simplification\uff1a\u5220\u53bb\u67d0\u4e9b\u8fb9\u6216\u4e09\u89d2\u5f62\uff0c\u4f46\u7ef4\u6301\u8fde\u63a5\u5173\u7cfb\u3002</li> <li>Mesh Regularization\uff1a\u5c06\u4e09\u89d2\u5f62\u6b63\u5219\u5316\uff0c\u4f7f\u6bcf\u4e2a\u9762\u66f4\u63a5\u8fd1\u6b63\u4e09\u89d2\u5f62\uff0c\u4f46\u4e0d\u80fd\u4e22\u5931\u7ec6\u8282\u3002</li> </ul>"},{"location":"GAMES101/Lecture%2012%20Geometry%203/#mesh-subdivision","title":"Mesh Subdivision","text":"<p>\u4e09\u89d2\u5f62\u7ec6\u5206\uff1a\u5148\u589e\u52a0\u4e09\u89d2\u5f62\u6570\u91cf\uff0c\u518d\u7a0d\u5fae\u6539\u53d8\u5404\u4e2a\u4e09\u89d2\u5f62\u4f4d\u7f6e\uff0c\u4f7f\u5176\u6574\u4f53\u5f62\u6210\u4e0d\u540c\u7684\u5f62\u72b6\u3002</p>"},{"location":"GAMES101/Lecture%2012%20Geometry%203/#loop-subdivision","title":"Loop Subdivision","text":"<ul> <li>Split each triangle into four: \u8fde\u63a5\u4e09\u6761\u8fb9\u7684\u4e2d\u70b9\uff0c\u5c06\u539f\u4e09\u89d2\u5f62\u5206\u6210\u56db\u4e2a</li> <li>Assign new vertex positions according to weights: new and old vertices updated differently</li> </ul> <p>\u600e\u4e48 update\uff1f</p> <ol> <li>\u65b0\u70b9\uff1a    \u5f53\u524d\u70b9\u6240\u5728\u7684\u8fb9\u88ab\u4e24\u4e2a\u4e09\u89d2\u5f62\u5171\u7528\u3002\u8fd9\u6761\u8fb9\u7684\u4e24\u4e2a\u9876\u70b9\u8bb0\u4e3a A\u3001B\uff0c\u4e24\u4e09\u89d2\u5f62\u7684\u5269\u4f59\u4e24\u4e2a\u9876\u70b9\u8bb0\u4e3a C\u3001D\uff0c\u5219\u5f53\u524d\u70b9\u53d8\u6362\u540e\u7684\u5750\u6807\u4e3a 3/8*(A+B)+1/8*(C+D)    \uff08A \u548c B \u79bb\u65b0\u70b9\u66f4\u8fd1\uff0c\u5f71\u54cd\u5927\uff0c\u6743\u91cd\u5927\uff09</li> </ol> <p>{style=\"width:400px\"}</p> <ol> <li>\u539f\u6709\u7684\u70b9\uff1a    \u548c\u5f53\u524d\u70b9\u76f8\u90bb\u7684\u539f\u6709\u7684\u70b9\u7684\u4e2a\u6570\u662f\u5f53\u524d\u70b9\u7684\u5ea6 n\u3002    u \u662f\u5e38\u6570\uff0cn=3 \u65f6 u=3/16\uff0c\u5426\u5219 u=3/(8n)\u3002    \u5f53\u524d\u70b9\u53d8\u6362\u540e\u7684\u5750\u6807\u4e3a\uff1a(1-n*u)*\u5f53\u524d\u70b9\u539f\u5148\u7684\u5750\u6807+u*\u6240\u6709\u76f8\u90bb\u70b9\u5750\u6807\u4e4b\u548c\u3002</li> </ol>"},{"location":"GAMES101/Lecture%2012%20Geometry%203/#catmull-clark-subdivision","title":"Catmull-Clark Subdivision","text":"<p>Loop Subdivision \u53ea\u80fd\u7528\u4e8e\u4e09\u89d2\u5f62\u9762\u7684\u7ec6\u5206\uff0c\u800c Catmull-Clark Subdivision \u53ef\u7528\u4e8e\u4efb\u610f\u5f62\u72b6\u9762\u7684\u7ec6\u5206\u3002</p> <p>\u5b9a\u4e49\uff1a</p> <ul> <li>\u56db\u8fb9\u5f62\u9762\uff08quad face\uff09\u548c\u975e\u56db\u8fb9\u5f62\u9762\uff08non-quad face\uff09</li> <li>\u5ea6\uff08degree\uff09\uff1a\u4e00\u4e2a\u9876\u70b9\u8fde\u63a5\u7684\u8fb9\u6570</li> <li>\u5947\u5f02\u70b9\uff08extraordinaty vertex\uff09\uff1a\u5ea6\u4e0d\u7b49\u4e8e\u56db\u7684\u9876\u70b9</li> </ul> <p>\u6b65\u9aa4\uff1a</p> <ol> <li>\u53d6\u6bcf\u6761\u8fb9\u7684\u4e2d\u70b9\u548c\u6bcf\u4e2a\u9762\u7684\u4e2d\u70b9</li> <li>\u8fde\u63a5\u6240\u6709\u4e2d\u70b9</li> <li>\u8c03\u6574\u9876\u70b9\u7684\u4f4d\u7f6e</li> </ol> <p>\u7ec6\u5206\u540e\u539f\u6709\u7684\u5947\u5f02\u70b9\u4ecd\u7136\u662f\u5947\u5f02\u70b9\uff0c\u539f\u6765\u975e\u56db\u8fb9\u5f62\u9762\u7684\u4e2d\u70b9\u6210\u4e3a\u65b0\u7684\u5947\u5f02\u70b9\u3002 \u975e\u56db\u8fb9\u5f62\u9762\u7ec6\u5206\u4e3a\u591a\u4e2a\u56db\u8fb9\u5f62\u9762\u3002 \u2014\u2014\u6709\u975e\u56db\u8fb9\u5f62\u9762\uff0c\u5219\u7ec6\u5206\u540e\u589e\u52a0\u76f8\u5e94\u6570\u91cf\u7684\u5947\u5f02\u70b9\uff1b\u4e00\u6b21\u7ec6\u5206\u540e\u4e0d\u5b58\u5728\u975e\u56db\u8fb9\u5f62\u9762\uff0c\u5947\u5f02\u70b9\u6570\u4e0d\u589e\u52a0\u3002</p> <p>\u600e\u4e48\u66f4\u65b0\uff1f\uff08\u7565\uff09</p> <ol> <li>\u65b0\u7684\u9762\u4e2d\u5fc3\u7684\u70b9\uff1a\u7528\u9762\u7684\u9876\u70b9\u76f4\u63a5\u5e73\u5747</li> <li>\u65b0\u7684\u8fb9\u4e2d\u5fc3\u7684\u70b9\uff1a\u7528\u8fb9\u7684\u9876\u70b9\u548c\u76f8\u90bb\u7684\u9762\u7684\u4e2d\u5fc3\u70b9\uff0c\u76f4\u63a5\u5e73\u5747</li> <li>\u539f\u5148\u7684\u70b9\uff1a\u7528\u76f8\u90bb\u7684\u8fb9\u4e2d\u5fc3\u70b9\u548c\u9762\u4e2d\u5fc3\u70b9\u52a0\u6743\u5e73\u5747</li> </ol>"},{"location":"GAMES101/Lecture%2012%20Geometry%203/#mesh-simplification","title":"Mesh Simplification","text":"<p>e.g. Edge Collapse\uff1a \u5c06\u67d0\u4e9b\u8fb9\u7684\u4e24\u4e2a\u9876\u70b9\u91cd\u5408\u6210\u4e00\u4e2a\u3002</p> <p>\u600e\u4e48\u786e\u5b9a\u54ea\u4e9b\u8fb9\u574d\u7f29\uff1f</p> <p>Quadric Error Metrics: \u4e8c\u6b21\u8bef\u5dee\uff08Quadric Error\uff09\uff1a\u4e00\u4e2a\u70b9\u5230\u76f8\u5173\u7684\u51e0\u4e2a\u9762\u7684\u8ddd\u79bb\u5e73\u65b9\u548c \u8fb9\u574d\u7f29\u65f6\uff0c\u5c06\u65b0\u7684\u9876\u70b9\u653e\u5728\u67d0\u4e2a\u6700\u4f73\u4f4d\u7f6e\uff0c\u4f7f\u5176\u4e8c\u6b21\u8bef\u5dee\u6700\u5c0f</p> <p>\u5148\u8ba1\u7b97\u6240\u6709\u70b9\u7684\u6700\u5c0f\u4e8c\u6b21\u8bef\u5dee\uff0c\u4ece\u5c0f\u5230\u5927\u4f9d\u6b21\u6309\u4e8c\u6b21\u8bef\u5dee\u7684\u5927\u5c0f\u574d\u7f29\u3002 \u6bcf\u6b21\u574d\u7f29\u540e\uff0c\u5468\u56f4\u70b9\u7684\u4e8c\u6b21\u8bef\u5dee\u4f1a\u88ab\u5f71\u54cd\uff0c\u8981\u66f4\u65b0\u5468\u56f4\u70b9\u3002</p> <p>\u6570\u636e\u7ed3\u6784\uff1a\u4f18\u5148\u961f\u5217/\u5806</p>"},{"location":"GAMES101/Lecture%2012%20Geometry%203/#shadow-mapping-dot-light","title":"Shadow Mapping (dot light)","text":"<ul> <li>\u786c\u9634\u5f71\uff1a\u9634\u5f71\u8fb9\u7f18\u9510\u5229\uff0c\u6240\u6709\u50cf\u7d20\u8981\u4e48\u5728\u9634\u5f71\u8981\u4e48\u4e0d\u5728\u9634\u5f71  </li> <li>\u8f6f\u9634\u5f71\uff1a\u9634\u5f71\u5e73\u6ed1\u8fc7\u6e21</li> </ul> <p>\u8d8a\u9760\u8fd1\u7269\u4f53\u5e95\u90e8\uff0c\u9634\u5f71\u8d8a\u786c\uff08\u672c\u5f71\uff09\uff1b\u8d8a\u8fdc\u79bb\u7269\u4f53\u5e95\u90e8\uff0c\u9634\u5f71\u8d8a\u8f6f\uff08\u534a\u5f71\uff09</p> <p>Key idea: the point NOT in shadow must be seen both by the light and by the camera.</p> <p>\u6b65\u9aa4\uff1a</p> <ol> <li>\u4ece\u5149\u6e90\u770b\u5411\u573a\u666f\uff0c\u8bb0\u5f55\u80fd\u770b\u5230\u7684\u70b9\u7684\u6df1\u5ea6  </li> <li>\u4ece\u76f8\u673a\u770b\u5411\u573a\u666f\uff0c\u67e5\u770b\u770b\u5230\u7684\u70b9\u5728\u4e0a\u4e00\u6b65\u4e2d\u8bb0\u5f55\u7684\u6df1\u5ea6\uff0c\u6bd4\u8f83\u8bb0\u5f55\u7684\u6df1\u5ea6\u548c\u5b9e\u9645\u5230\u5149\u6e90\u7684\u6df1\u5ea6\u3002\u5982\u679c\u4e24\u6b21\u6df1\u5ea6\u4e00\u6837\uff0c\u5219\u8be5\u70b9\u80fd\u88ab\u770b\u5230</li> </ol> <p>{style=\"width:400px\"}</p> <p>\u95ee\u9898\uff1a \u6d6e\u70b9\u6570\u7cbe\u5ea6\u95ee\u9898\uff0c\u76f8\u7b49\u6709\u504f\u5dee shadow map\u7684\u5206\u8fa8\u7387\u548c\u6574\u4e2a\u56fe\u50cf\u7684\u5206\u8fa8\u7387\u5e94\u5bf9\u5e94\uff0c\u5f00\u9500\u5927</p>"},{"location":"GAMES101/Lecture%2013%20Ray%20Tracing%201/","title":"Lec13 Ray Tracing 1 (Whitted-Style Ray Tracing)","text":"<p>Why ray tracing?</p> <p>Rasterization couldn't handle global effects well. e.g. soft shadows, and especially when the light bounces more than once (glossy relection, indirect illumination).</p> <p>Rasterization is fast, but quality is relatively low. Ray tracing is accurate, but is very slow. Rasterization: real-time; ray tracing: offline</p> <p>Three ideas about light rays:</p> <ul> <li>Light travels in straight lines</li> <li>Light rays do not \"collide\" with each other if thay cross</li> <li>Light rays travel from the light sources to the eye (but the physics is invariant under path reversal - reviprocity)</li> </ul> <p>\u57fa\u672c\u65b9\u6cd5\uff1a</p> <p>\u5bf9\u6bcf\u4e00\u4e2a\u50cf\u7d20\uff0c\u4ece\u76f8\u673a\u51fa\u53d1\u8fde\u7ebf\u7a7f\u8fc7\u50cf\u7d20\uff08eye ray\uff09\uff0c\u6253\u5230\u573a\u666f\u4e2d\u6700\u8fd1\u7684\u4ea4\u70b9\uff08closest scene\uff09\uff0c\u518d\u5c06\u8fd9\u4e2a\u70b9\u548c\u5149\u6e90\u8fde\u7ebf\uff08shadow ray\uff09\u3002\u5982\u679c\u80fd\u8fde\u7ebf\uff0c\u5219\u8fd9\u4e2a\u70b9\u80fd\u88ab\u5149\u6e90\u53ef\u89c1\u3002</p>"},{"location":"GAMES101/Lecture%2013%20Ray%20Tracing%201/#whitted-style-ray-tracing","title":"Whitted-Style Ray Tracing","text":"<p>Whitted \u98ce\u683c\uff1a\u5728\u4efb\u610f\u70b9\u5149\u7ebf\u53ef\u7ee7\u7eed\u4f20\u64ad\uff08\u53cd\u5c04\uff0c\u6298\u5c04...\uff09</p> <p>\u7740\u8272\u65f6\uff0c\u5728\u6bcf\u4e00\u4e2a\u5f39\u8df3\u7684\u70b9\u5224\u65ad\u80fd\u5426\u88ab\u5149\u6e90\u7167\u4eae\uff0c\u8003\u8651\u80fd\u91cf\u635f\u5931\u3002\u6700\u7ec8\u50cf\u7d20\u7684\u7740\u8272\u662f\u6240\u6709\u5f39\u8df3\u70b9\u7684\u7740\u8272\u4e4b\u548c\u3002</p> <p>\u4ece\u76f8\u673a\u548c\u50cf\u7d20\u8fde\u63a5\u7684\u5149\u7ebf\u662fprimary ray\uff0c\u5f39\u8df3\u540e\u5f62\u6210\u7684\u5149\u7ebf\u662fsecondary ray\uff0c\u548c\u5149\u6e90\u8fde\u63a5\u7684\u5149\u7ebf\u662fshadow ray\u3002</p> <p>{style=\"width:500px\"}</p>"},{"location":"GAMES101/Lecture%2013%20Ray%20Tracing%201/#ray-surface-intersection","title":"Ray-Surface Intersection","text":"<p>Ray Equation:</p> <p>Ray is defined by its origin and a direction vector.</p> \\[\\mathbf{r}(t)=\\mathbf{o}+t\\mathbf{d}\\qquad 0\\le t&lt;\\infty\\] <p>(ray(time) = origin + time * direction)</p> <p>Ray intersection with sphere:</p> <p>\u8054\u7acb\u5149\u7ebf\u65b9\u7a0b\u548c\u7403\u7684\u65b9\u7a0b\uff0c\u89e3\u4e8c\u6b21\u65b9\u7a0b\u3002  \u6839\u636e\u89e3\u7684\u4e2a\u6570\u5206\u4e3a\u76f8\u79bb\u3001\u76f8\u4ea4\u548c\u76f8\u5207\u3002\u76f8\u4ea4\u65f6\u53d6\u66f4\u8fd1\u7684\u70b9\u3002</p>"},{"location":"GAMES101/Lecture%2013%20Ray%20Tracing%201/#ray-intersection-with-implicit-surface","title":"Ray intersection with implicit surface:","text":"\\[ \\begin{cases}     \\mathbf{r}(t)=\\mathbf{o}+t\\mathbf{d},\\,\\,0\\le t&lt;\\infty \\\\     \\mathbf{p}: f(\\mathbf{p})=0 \\end{cases} \\] <p>Substitute ray equation:</p> \\[f(\\mathbf{o}+t\\mathbf{d})=0\\] <p>Solve for real, positive roots.</p> <p>How to compute?</p> <p>Simple idea: just intersect ray with each triangle. Ignore multiple intersections, each ray can have 0 or 1 intersections.</p>"},{"location":"GAMES101/Lecture%2013%20Ray%20Tracing%201/#ray-intersection-with-triangle","title":"Ray Intersection with Triangle","text":"<ol> <li>ray-plane intersection  </li> <li>test if hit point is inside triangle</li> </ol> <p>Plane equation: </p> <p>plane is defined by normal vector (N) and a  point (P') on plane.</p> \\[\\mathbf{p}:(\\mathbf{p}-\\mathbf{p}')\\cdot N=0\\] <p>Solve for intersection:</p> \\[ (\\mathbf{p}-\\mathbf{p}')\\cdot N=(\\mathbf{o}+t\\mathbf{d}-\\mathbf{p}')\\cdot N=0 \\\\[0.5em]\\\\ t=\\frac{(-\\mathbf{p}'-\\mathbf{o})\\cdot N}{\\mathbf{d}\\cdot N} \\] <p>Then test if \\(\\mathbf{o}+t\\mathbf{d}\\) is inside triangle.</p> <p>Faster: Moller Trunbore Algorithm</p> <p>Give barycentric coordinate directly.</p> \\[\\mathbf{O}+t\\mathbf{D}=(1-b_1-b_2)\\mathbf{P}_0-b_1\\mathbf{P}_1+b_2\\mathbf{P}_2\\] <p>where \\(t\\), \\(b_1\\) and \\(b_2\\) are variables.</p> \\[ \\begin{bmatrix} t \\\\ b_1 \\\\ b_2 \\end{bmatrix}= \\frac{1}{\\mathbf{S}_1\\cdot\\mathbf{E}_1} \\begin{bmatrix} \\mathbf{S}_2\\cdot\\mathbf{E}_2 \\\\ \\mathbf{S}_1\\cdot\\mathbf{S} \\\\ \\mathbf{S}_2\\cdot\\mathbf{D} \\end{bmatrix} \\] <p>where</p> \\[ \\begin{align*} \\mathbf{E}_1&amp;=\\mathbf{P}_1-\\mathbf{P}_0 \\\\ \\mathbf{E}_2&amp;=\\mathbf{P}_2-\\mathbf{P}_0 \\\\ \\mathbf{S}&amp;=\\mathbf{O}-\\mathbf{P}_0 \\\\ \\mathbf{S}_1&amp;=\\mathbf{D}\\times\\mathbf{E}_2 \\\\ \\mathbf{S}_2&amp;=\\mathbf{S}\\times\\mathbf{E}_1 \\end{align*} \\]"},{"location":"GAMES101/Lecture%2013%20Ray%20Tracing%201/#ray-intersection-with-axis-aligned-box","title":"Ray Intersection with Axis-Aligned Box","text":"<p>Bounding Volumes : Quick way to avoid intersections: bound complex object with a simple volume.</p> <p>Box: the intersection of 3 pairs of slabs. esp. we often use an Axis-Aligned Bounding Box (AABB), any side of the BB is along either x, y, or z axis.</p> <p>Key ideas:</p> <ul> <li>The ray enters the box only when it enters all pairs of s;abs.  </li> <li>The ray exits the box as long as it exits any pair of slabs.</li> </ul> <p>For the 3D box, \\(t_{enter}=max\\{t_{min}\\}, t_{exit}=min\\{t_{max}\\}\\)</p> <p>If \\(t_{exit}&lt;0\\), the box is \"behind\" the ray, no intersections.</p> <p>Else if \\(t_{exit}\\ge 0\\) and \\(t_{enter}&lt;0\\), the ray's origin is inside the box, have intersections.</p> <p>If \\(t_{enter}&lt;t_{exit}\\), the ray stays a while in the box, so they must intersect.</p> <p>In Summary, ray and AABB intersect iff \\(t_{enter}&lt;t_{exit}\\) and \\(t_{exit} \\ge 0\\).</p>"},{"location":"GAMES101/Lecture%2014%20Ray%20Tracing%202/","title":"Lec14 Ray Tracing 2(Acceleration)","text":""},{"location":"GAMES101/Lecture%2014%20Ray%20Tracing%202/#uniform-spatial-partitions-grids","title":"Uniform Spatial Partitions (Grids)","text":"<p>Preprocesss: Build Acceleration Grid</p> <ol> <li>Find bounding box</li> <li>Create grid</li> <li>Store each object in overlapping cells (\u5c06\u548c\u7269\u4f53\u8868\u9762\u6709\u76f8\u4ea4\u7684\u5404\u81ea\u6807\u8bb0)</li> <li>Step through grid in ray traversal order</li> </ol> <p>\u8ba4\u4e3a\u5149\u7ebf\u548c\u76d2\u5b50\u6c42\u4ea4\u8ba1\u7b97\u5feb\u3001\u5149\u7ebf\u548c\u7269\u4f53\u6c42\u4ea4\u8ba1\u7b97\u6162</p> <p>\u6839\u636e\u5149\u7ebf\u7684\u65b9\u5411\u5927\u81f4\u5224\u65ad\u548c\u54ea\u4e9b\u76d2\u5b50\u76f8\u4ea4\u3002 \u5f53\u5149\u7ebf\u548c\u76d2\u5b50\u76f8\u4ea4\u4f46\u76d2\u5b50\u91cc\u6ca1\u6709\u7269\u4f53\uff08\u6ca1\u88ab\u6807\u8bb0\uff09\u65f6\uff0c\u8df3\u8fc7\uff1b \u5f53\u5149\u7ebf\u548c\u76d2\u5b50\u76f8\u4ea4\u4f46\u76d2\u5b50\u91cc\u6709\u7269\u4f53\u65f6\uff0c\u8ba1\u7b97\u662f\u5426\u548c\u7269\u4f53\u76f8\u4ea4\u3002</p> <p>\u82e5\u53ea\u9700\u8981\u627e\u6700\u8fd1\u4ea4\u70b9\uff0c\u627e\u5230\u4ea4\u70b9\u540e\u505c\u6b62\u3002</p> <p>\u600e\u4e48\u786e\u5b9a\u5212\u5206\u7684\u683c\u5b50\u6570\uff1f</p> <p>\u683c\u5b50\u592a\u5c11\uff0c\u52a0\u901f\u6548\u679c\u5dee\uff1b\u683c\u5b50\u592a\u591a\uff0c\u5149\u7ebf\u548c\u76d2\u5b50\u7684\u8ba1\u7b97\u589e\u52a0\u3002</p> <p>\u683c\u5b50\u6570=C*\u573a\u666f\u4e2d\u7269\u4f53\u6570\uff0c\u5176\u4e2d 3D \u65f6 C \u7ea6\u4e3a 27\u3002</p> <p>\u52a0\u901f\u6548\u679c\uff1f</p> <p>\u573a\u666f\u4e2d\u7269\u4f53\u5206\u5e03\u5747\u5300\u3001\u7269\u4f53\u591a\u65f6\uff0c\u52a0\u901f\u6548\u679c\u597d\uff1b \u573a\u666f\u4e2d\u7269\u4f53\u5206\u5e03\u4e0d\u5747\u5300\u3001\u90e8\u5206\u533a\u57df\u7a7a\u65f7\u65f6\uff0c\u52a0\u901f\u6548\u679c\u5dee\uff1b</p>"},{"location":"GAMES101/Lecture%2014%20Ray%20Tracing%202/#spatial-partition","title":"Spatial Partition","text":""},{"location":"GAMES101/Lecture%2014%20Ray%20Tracing%202/#kd-tree-pre-processing","title":"KD-Tree Pre-Processing","text":"<p>Spatial partition examples:</p> <ul> <li>Oct-Tree\uff08\u516b\u53c9\u6811\uff09   \u5c06\u6574\u4e2a\u573a\u666f\u7528\u5305\u56f4\u76d2\u5305\u56f4\uff0c\u5206\u6210 8 \u5757\uff083D\uff09\uff0c\u5bf9\u6bcf\u4e00\u4e2a\u5206\u6210\u7684\u533a\u57df\u518d\u5206\u6210 8 \u5757\uff0c\u76f4\u5230\u5176\u4e2d\u4e00\u5757\u4e2d\u7269\u4f53\u6570\u91cf\u8db3\u591f\u5c11</li> <li>KD-Tree   \u6bcf\u6b21\u5206\u5272\u65f6\u4ec5\u5206\u6210\u4e24\u5757\uff0c\u5206\u5272\u65b9\u5411 xyz \u4ea4\u66ff</li> <li>BSP-Tree   \u6bcf\u6b21\u5206\u5272\u65f6\u4ec5\u5206\u6210\u4e24\u5757\uff0c\u65b9\u5411\u4efb\u610f</li> </ul> <p>{style=\"width:500px\"}</p> <p>KD-Tree storage:</p> <p>Internal nodes store:</p> <ul> <li>split axis: x-, y- or z-</li> <li>split position: coordinate of split plane along axis</li> <li>children: pointers to child nodes</li> </ul> <p>Leaf nodes store:</p> <ul> <li>list of objects</li> </ul> <p>Traversing a KD-Tree:</p> <p>\u4ece\u6574\u4e2a\u573a\u666f\u5f00\u59cb\uff0c\u5982\u679c\u6709\u4ea4\u70b9\uff0c\u5219\u770b\u548c\u5b50\u8282\u70b9\u5bf9\u5e94\u7684\u76d2\u5b50\u662f\u5426\u6709\u4ea4\u70b9\uff0c\u76f4\u5230\u68c0\u67e5\u5b8c\u6240\u6709\u6709\u4ea4\u70b9\u7684\u53f6\u8282\u70b9\u3002</p> <p>{style=\"width:400px\"}</p> <p>\u95ee\u9898\uff1a</p> <ol> <li>\u9700\u8981\u77e5\u9053\u5305\u56f4\u76d2\u548c\u54ea\u4e9b\u4e09\u89d2\u5f62\u76f8\u4ea4</li> <li>\u4e00\u4e2a\u7269\u4f53\u53ef\u51fa\u73b0\u5728\u591a\u4e2a\u5305\u56f4\u76d2\u4e2d</li> </ol>"},{"location":"GAMES101/Lecture%2014%20Ray%20Tracing%202/#object-partition-bounding-volume-hierarchy-bvh","title":"Object Partition &amp; Bounding Volume Hierarchy (BVH)","text":"<p>\u6bcf\u6b21\u5212\u5206\u5c06\u4e09\u89d2\u5f62\u5206\u6210\u4e24\u7ec4\uff0c\u5206\u522b\u91cd\u65b0\u6c42\u5305\u56f4\u76d2</p> <p>BVH \u4e2d\u4e00\u4e2a\u7269\u4f53\u53ea\u51fa\u73b0\u5728\u4e00\u4e2a\u5305\u56f4\u76d2\u4e2d\uff0c\u4e0d\u540c\u7684\u5305\u56f4\u76d2\u53ef\u80fd\u76f8\u4ea4</p> <p>KD-Tree \u5212\u5206\u7a7a\u95f4\uff0cBVH \u5212\u5206\u7269\u4f53\u3002\u5b9e\u9645 BVH \u5e94\u7528\u66f4\u5e7f\u6cdb\u3002</p> <p>{style=\"width:400px\"}</p> <p>How to subdivide a node?</p> <p>Choose a dimension to split</p> <ul> <li>1: Always choose the longest axis in node</li> <li>2: Split node at locaton of median object (balances tree)</li> </ul> <p>Termination criteria?</p> <p>Stop when node contains few elements (e.g. 5)</p> <p>BVH traversal</p> <pre><code>Intersect(Ray ray, BVH node) {\n  if (ray misses node.bbox) return;\n\n  if (node is a leaf node) {\n    test intersection with all objs;\n    return closet intersection;\n  }\n\n  hit1 = Intersect(ray, node.child1);\n  hit2 = Intersect(ray, node.child2);\n  return the closer of hit1, hit2;\n}\n</code></pre>"},{"location":"GAMES101/Lecture%2014%20Ray%20Tracing%202/#basic-radiometry","title":"Basic Radiometry","text":"<p>Measurement system and units for illumination.</p> <p>Accurate measure the spatial properties of light New terms: radiant flux, intersity, irradiance, radiance</p> <p>Perform lighting calculation in a physically correct manner</p>"},{"location":"GAMES101/Lecture%2014%20Ray%20Tracing%202/#radiant-energy-and-flux-power","title":"Radiant Energy and Flux (Power)","text":"<p>Radiant energy is the energy of electromagnetic radiation. It is measured in units of joules, and denoted by the symbol:</p> \\[Q\\,[J=Joule]\\] <p>Radiant flux (power) is the energy emitted, reflected, transmitted or received, per unit time.</p> \\[\\Phi\\equiv\\frac{\\mathrm{d}Q}{\\mathrm{d}t}\\,[W=Watt]\\,[ln=lumen]\\] <p>Flux: photons flowing through a sensor in unit time</p>"},{"location":"GAMES101/Lecture%2014%20Ray%20Tracing%202/#radiant-intensity","title":"Radiant Intensity","text":"<p>Radiant (luminous) intensity is the power per unit solid angle emitted by a point light source.</p> <p>{style=\"width:200px\"}</p> \\[I(\\omega)\\equiv\\frac{\\mathrm{d}\\Phi}{\\mathrm{d}\\omega}\\] \\[\\left[\\frac{W}{sr}\\right]\\,\\left[\\frac{lm}{sr}=cd=candela\\right]\\] <p>Angles and solid angles</p> <p>Angle: ratio of subtended arc length on circle to radius</p> <ul> <li>\\(\\theta=frac{l}{r}\\)</li> <li>Circle has \\(2\\pi\\) radians</li> </ul> <p>Solid angle: ratio of subtended area on sphere to radius squared</p> <ul> <li>\\(\\Omega=\\frac{A}{r^2}\\)</li> <li>Sphere has \\(4\\pi\\) steradians</li> </ul> <p>Differential solid angles:</p> <p>{style=\"width:250px\"}</p> \\[ \\begin{align*} \\mathrm{d}A&amp;=(r\\mathrm{d}\\theta)(r\\sin\\theta\\mathrm{d}\\phi)\\\\ &amp;=r^2\\sin\\theta\\mathrm{d}\\theta\\mathrm{d}\\phi \\end{align*} \\] \\[\\mathrm{d}\\omega=\\frac{\\mathrm{d}A}{r^2}=\\sin\\theta\\mathrm{d}\\theta\\mathrm{d}\\phi\\] <p>Sphere:</p> \\[ \\begin{align*} \\Omega&amp;=\\int_{S^2}\\mathrm{d}\\omega \\\\ &amp;=\\int_0^{2\\pi}\\int_0^{\\pi}\\sin\\theta\\mathrm{d}\\theta\\mathrm{d}\\phi \\\\ &amp;=4\\pi \\end{align*} \\] <p>Isotropic point source:</p> \\[ \\begin{align*} \\Phi&amp;=\\int_{S^2}I\\mathrm{d}\\omega \\\\ &amp;=4\\pi I \\end{align*} \\] \\[I=\\frac{\\Phi}{4\\pi}\\]"},{"location":"GAMES101/Lecture%2015%20Ray%20Tracing%203/","title":"Lec15 Ray Tracing 3(Light Transport & Global Illumination)","text":""},{"location":"GAMES101/Lecture%2015%20Ray%20Tracing%203/#irradiance-and-radiance","title":"Irradiance and Radiance","text":"<p>Irradiance is the power per (perpendicular / projected) unit area incident on a surfacee  point.</p> <p>{style=\"width:200px\"}</p> \\[ E(\\mathbf{x})\\equiv\\frac{\\mathrm{d}\\Phi(\\mathbf{x})}{\\mathrm{d}A} \\] \\[ \\left[\\frac{\\text{W}}{\\text{m}^2}\\right]\\,\\left[\\frac{\\text{lm}}{\\text{m}^2}=\\text{lux}\\right] \\] <p>In Blinn-Phong model, \"intensity falloff\" should be corrected as \"irradiance falloff\".</p> <p>Radiance is the fundamental field quantity that describes the distribution of light in an environment.</p> <ul> <li>Radiance is the quantity associated with a ray  </li> <li>Rendering is all about computing radiance</li> </ul> <p>Radiance is the power per unit solid angle, per projected unit area.</p> <p>{style=\"width:200px\"}</p> \\[ L(\\mathrm{p},\\omega)\\equiv\\frac{\\mathrm{d}\\Phi(\\mathrm{p},\\omega)}{\\mathrm{d}\\mathrm{d}A\\cos\\theta} \\] \\[ \\left[\\frac{\\mathrm{W}}{\\mathrm{sr}\\,\\mathrm{m}^2}\\right]\\,\\left[\\frac{\\mathrm{cd}}{\\mathrm{m}^2}=\\frac{\\mathrm{lm}}{\\mathrm{sr}\\,\\mathrm{m}^2}=\\mathrm{nit}\\right] \\] <ul> <li>Radiance is irradiance per solid angle  </li> <li>Radiance is intensity per projected area</li> </ul> <p>Irradiance vs. radiance</p> <p>Irradiance is total power received by area dA, from all angle.</p> \\[ \\begin{align*} dE(\\mathrm{p},\\omega)&amp;=L_i(\\mathrm{p},\\omega)\\cos\\theta\\mathrm{d}\\omega \\\\ E(\\mathrm{p})&amp;=\\int_{H^2}L_i(\\mathrm{p},\\omega)\\cos\\theta\\mathrm{d}\\omega \\end{align*} \\]"},{"location":"GAMES101/Lecture%2015%20Ray%20Tracing%203/#bidirectional-reflectance-distribution-function-brdf","title":"Bidirectional Reflectance Distribution Function (BRDF)","text":"<p>Radiance from direction \\(\\omega_i\\) turns into the power E that dA receives. Then power E will become the radiance to any other direction \\(\\omega\\). </p> <p>BRDF represents how much light is reflected into each outgoing direction \\(\\omega_r\\) from each incoming direction.</p> <p>{style=\"width:300px\"}</p> \\[ f_r(\\omega_i\\to\\omega_r)=\\frac{\\mathrm{d}L_r(\\omega_r)}{\\mathrm{d}E_i(\\omega_i)}=\\frac{\\mathrm{d}L_r(\\omega_r)}{L_i(\\omega_i)\\cos\\theta_i\\mathrm{d}\\omega_i} \\quad\\left[\\frac{1}{\\text{sr}}\\right] \\] <p>The reflection equation:</p> \\[ L_r(\\mathrm{p},\\omega_r)=\\int_{H^2}f_r(\\mathrm{p},\\omega_i\\to\\omega_r)L_i(\\mathrm{p},\\omega_i)\\cos\\theta_i\\mathrm{d}\\omega_i \\] <p>The rendering equation:</p> <p>Add an emission term to make it general.</p> \\[ L_o(\\mathrm{p},\\omega_o)=L_e(\\mathrm{p},\\omega_o)+\\int_{\\Omega^+}L_i(\\mathrm{p},\\omega_i)f_r(\\mathrm{p},\\omega_i,\\omega_o)(n\\cdot\\omega_i)\\mathrm{d}\\omega_i \\] <p>(reflected light = emission + incident lignt * BRDF * incident angle)</p> <p>One point light: no need of integral Multiple point lights: sum over all light sources Area light: replace sum with integal Unknown reflection: regard reflection as light source</p> <p>{style=\"width:400px\"}</p> <p>Simplify: L=E+KL</p> <p>Approximate set of all paths of light in scene:</p> \\[ \\begin{align*} L&amp;=E+KL \\\\ L&amp;=(I-K)^{-1}E \\\\ &amp;=(I+K+K^2+K^3+\\cdots)E \\\\ &amp;=E+KE+K^2E+K^3E+\\cdots \\end{align*} \\] <ul> <li>\\(E\\): emission directly from light sources  </li> <li>\\(KE\\): direct illumination on surfaces  </li> <li>\\(K^2E\\): indirect illumination (one bounce indirect)   </li> <li>...</li> </ul>"},{"location":"GAMES101/Lecture%2015%20Ray%20Tracing%203/#probability-review","title":"Probability Review","text":"<p>\\(X\\): random variable \\(X\\sim p(x)\\): probability density function (PDF)</p> <p>Requirements of a probability distrubution:</p> \\[p_i\\ge0\\quad\\sum_{i=1}^n p_i=1\\] <p>Expected value:</p> \\[E[X]=\\sum_{i=1}^n x_i p_i\\] <p>Continuous case: PDF</p> <p>Conitions on p(x):      \\(p(x)\\ge 0\\,\\text{and}\\,\\int p(x)dx=1\\) Expected value of X:    \\(E[X]=\\int xp(x)dx\\)</p> <p>Function of a Random Variable</p> \\[X\\sim p(x)\\quad Y=f(X)\\] <p>Expected value of a function of a random varaible:</p> \\[E[Y]=E[f(X)]=\\int f(x)p(x)dx\\]"},{"location":"GAMES101/Lecture%2016%20Ray%20Tracing%204/","title":"Lec16 Ray Tracing 4(Monte Carlo Path Tracing)","text":""},{"location":"GAMES101/Lecture%2016%20Ray%20Tracing%204/#monte-carlo-integration","title":"Monte Carlo Integration","text":"<p>Why: we want to solve an integral, but it can be too difficult to solve \\(\\int_a^b f(x)dx\\) analytically.</p> <p>What &amp; how: estimate the integral of a function by averaging random samples of the function's value.</p> <p>Monte Carlo estimator:</p> \\[X_i\\sim p(x)\\quad\\int_a^b f(x)dx \\] \\[\\int f(x)dx=\\frac{1}{N}\\sum_{i=1}^N\\frac{f(X_i)}{p(X_i)}\\] <ul> <li>The more samples, the less variance.</li> <li>Sample on X, integration on X.</li> </ul>"},{"location":"GAMES101/Lecture%2016%20Ray%20Tracing%204/#path-tracing","title":"Path Tracing","text":"<p>Problems of Whitted-Style:</p> <ul> <li>Glossy texure (Utah teapot)</li> <li>Color bleeding (Cornell box)</li> </ul> <p>A simple example: direct illumination</p> \\[ L_o(\\mathrm{p},\\omega_o)=\\int_{\\Omega^+}L_i(\\mathrm{p},\\omega_i)f_r(\\mathrm{p},\\omega_i,\\omega_o)(n\\cdot\\omega_i)\\mathrm{d}\\omega_i \\] <ul> <li>\\(f(x)\\): \\(L_i(\\mathrm{p},\\omega_i)f_r(\\mathrm{p},\\omega_i,\\omega_o)(n\\cdot\\omega_i)\\)</li> <li>\\(pdf(\\omega)\\): \\(1/2\\pi\\)</li> </ul> <p>Monte Carlo integration:</p> \\[ L_o(\\mathrm{p},\\omega_o)\\approx\\frac{1}{N}\\sum_{i=1}^N\\frac{L_i(\\mathrm{p},\\omega_i)f_r(\\mathrm{p},\\omega_i,\\omega_o)(n\\cdot\\omega_i)}{pdf(\\omega_i)} \\] <p>Code:</p> <pre><code>shade (p, wo)\n    Randomly choose N directions wi~pdf\n    Lo = 0.0\n    For each wi\n        Trace a ray r(p, wi)\n        If ray r hit the light\n            Lo += (1 / N) * L_i * f_r * cosine / pdf(wi)\n    Return Lo\n</code></pre> <p>Introduce global illumination:</p> <p>The light reflect from Q to P, equals to the direct illumination ar Q observed at P.</p> <pre><code>shade (p, wo)\n    Randomly choose N directions wi~pdf\n    Lo = 0.0\n    For each wi\n        Trace a ray r(p, wi)\n        If ray r hit the light\n            Lo += (1 / N) * L_i * f_r * cosine / pdf(wi)\n        Else If ray r hit an object at q\n            Lo += (1 / N) * shade(q, -wi) * f_r * cosine / pdf(wi)\n    Return Lo\n</code></pre> <p>Problems 1: Explosion of rays as bounces go up Rays will not explode iff N = 1.</p> <p>This is \"path tracing\".</p> <p>Code:</p> <pre><code>shade (p, wo)\n    Randomly choose ONE directions wi~pdf(w)\n    Lo = 0.0\n    For each wi\n        Trace a ray r(p, wi)\n        If ray r hit the light\n            Return L_i * f_r * cosine / pdf(wi)\n        Else If ray r hit an object at q\n            Return shade(q, -wi) * f_r * cosine / pdf(wi)\n</code></pre>"},{"location":"GAMES101/Lecture%2016%20Ray%20Tracing%204/#ray-generation","title":"Ray Generation","text":"<pre><code>ray_genaration(camPos, pixel)\n    Uniformly choose N sample positions within the pixel\n    pixel_radiance = 0.0\n    For each sample in the pixel\n        Shoot a ray t(camPos, cam_to_sample)\n        If ray r hit the scene at p\n            pixel_radiance += 1 / N * shade(p, sample_to_cam)\n    Return pixel_radiance\n</code></pre> <p>Problem 1: The recursion won't stop. Solution: Russian Roulette (RR)</p> <p>Suppose we manually set a probability P (0&lt;P&lt;1). With probability P, shoot a ray and return the shading result divided by P is Lo / P. With probability 1-P, don't shoot a ray adn you'll get 0.</p> <p>In this way, you can still expect to get Lo: E = P _ (Lo / P) + (1 - P) _ 0 = Lo</p> <p>Code:</p> <pre><code>(Add)\n    Manually specify a probability P_RR\n    Randomly select ksi in a uniform dist. in [0, 1]\n    If (ksi &gt; P_RR) retunr 0.0\n\n    Return ... / P_RR\n</code></pre> <p>Problem 2: Inefficient. When SPP (samplees per pixel) is low, get noisy results</p> <p>Only a few rays hit the light, so a lot of rays are \"wasted\".</p> <p>Solution: sample on the light</p> <p>Assume pdf = 1 / A. But the rendering equation intefrates on the solid angle.</p> <p>To sample on the light and integrate on the light, need the relationship between \\(d\\omega\\) and \\(dA\\).</p> <p>{style=\"width:400px\"}</p> \\[d\\omega=\\frac{dA\\cos\\theta'}{|| x'-x ||^2}\\] <p>Rewrite the rendering equation:</p> \\[ \\begin{align*} L_o(\\mathrm{p},\\omega_o)&amp;=\\int_{\\Omega^+}L_i(\\mathrm{p},\\omega_i)f_r(\\mathrm{p},\\omega_i,\\omega_o)\\cos\\theta\\,\\mathrm{d}\\omega_i \\\\ &amp;=\\int_A L_i(\\mathrm{p},\\omega_i)f_r(\\mathrm{p},\\omega_i,\\omega_o)\\frac{\\cos\\theta\\cos\\theta'}{|| x'-x ||^2}\\mathrm{d}A \\end{align*} \\] <p>Code:</p> <pre><code>shade(p, wo)\n    # Contribution from the light source.\n    Uniformlu sanple the light at x' (pdf_light = 1 / A)\n    L_dir = L_i * f_r * cos theta * cos theta' / |x' - p|^2 / pdf_light\n\n    # Contribution from other reflectors\n    L_indir = 0.0\n    Test Russian Roulette with probability P_RR\n    Uniformly sample the hemisphere toward wi (pdf_hemi = 1 / 2pi)\n    Trace a ray r(p, wi)\n    If ray r hir a non-emitting object ar q\n        L_indir = shade(q, -wi) * f_r * cos theta / pdf_hemi / P_RR\n\n    Return L_dir + L_indir\n</code></pre> <p>Final problem: need to test if the ray os not blocked in the middle.</p> <p>Hard to handle point light source.</p> <p>Things haven't covered:</p> <ul> <li>Uniformly sampling the hemisphere  </li> <li> <p>How? And in gengral. how to sample any function?   </p> </li> <li> <p>Monte Carlo intefration allows arbitatry pdfs  </p> </li> <li> <p>What's the best choice? (importance sampling)   </p> </li> <li> <p>Do random numbers matter?  </p> </li> <li> <p>Yes (low discrepancy sequences)  </p> </li> <li> <p>Sample the hemimsphere and the light  </p> </li> <li> <p>Can I combine them? Yes (multipe immp. sampling) </p> </li> <li> <p>The radiance of a pixel is the average of radiance on all paths passing through it  </p> </li> <li> <p>Why? (pixel reconstruction filter)  </p> </li> <li> <p>Is the radiance of a pixel the color of a pixel?  </p> </li> <li>No. (gamma correction, curves, color space)</li> </ul>"},{"location":"GAMES101/Lecture%2017%20Materials%20and%20Appearances/","title":"Lec17 Materials and Appearances","text":"<p>\u6e32\u67d3\u65b9\u7a0b\u4e2d\u7684 BRDF \u51b3\u5b9a\u7269\u4f53\u7684\u6750\u8d28\u3002Material == BRDF</p>"},{"location":"GAMES101/Lecture%2017%20Materials%20and%20Appearances/#diffuse-lambertian-material","title":"Diffuse / Lambertian Material","text":""},{"location":"GAMES101/Lecture%2017%20Materials%20and%20Appearances/#reflection","title":"Reflection","text":"<p>Light is equally reflected in each output direction.</p> <p>\u5047\u8bbe\u5404\u4e2a\u65b9\u5411\u8fdb\u5165\u7684\u5149\u5f3a\u5ea6\u76f8\u540c\uff0c\u5373\u5165\u5c04\u5149\u5747\u5300\u3002\u5047\u8bbe\u88ab\u7167\u5c04\u7684\u70b9\u65e2\u4e0d\u5438\u6536\u5149\u4e5f\u4e0d\u53d1\u51fa\u5149\u3002</p> <p>\u6839\u636e\u80fd\u529b\u5b88\u6052\uff0c\u8fdb\u5165\u7684\u80fd\u91cf\u548c\u53cd\u5c04\u51fa\u7684\u80fd\u91cf\u76f8\u7b49\u3002\u8fdb\u5165\u7684\u80fd\u91cf\u4e3a\u88ab\u7167\u5c04\u7684\u70b9\u5468\u56f4\u4e00\u5c0f\u5757\u533a\u57df\u63a5\u6536\u7684\u5149\uff0c\u5373\u5f53\u524d\u70b9\u7684 irradiance\u3002\u6240\u4ee5\u5165\u5c04\u548c\u51fa\u5c04\u7684 radiance \u76f8\u7b49\u3002</p> \\[ \\begin{align*} L_o(\\omega_o)&amp;=\\int_{H^2}f_r L_i(\\omega_i)\\cos\\theta_i\\mathrm{d}\\omega_i \\\\ &amp;=f_r L_i\\int_{H^2}\\cos\\theta_i\\mathrm{d}\\omega_i \\\\ &amp;=\\pi f_r L_i \\end{align*} \\] <p>\u6545\u5e38\u6570 BRDF \u4e3a\uff1a</p> \\[f_r=\\frac{\\rho}{\\pi}\\] <p>\u5176\u4e2d\\(\\rho\\)\u4e3a albedo \u7cfb\u6570\uff0c\u53ef\u4ee5\u4e3a\u5e38\u6570\uff0c\u53ef\u4ee5\u4e3a RGB \u5206\u5f00\u8bbe\u7f6e\u3002</p> <p>Glossy material:</p> <p>{style=\"width:300px\"}</p> <p>Refractive material:</p> <p>{style=\"width:300px\"}</p> <p>Perfect Specular Reflection</p> <p>{style=\"width:400px\"}</p> \\[ \\omega_o +\\omega_i=2(\\omega_i\\cdot\\vec{n})\\vec{n} \\\\[10pt] \\Rightarrow\\,\\omega_o=-\\omega_i+2(\\omega_i\\cdot\\vec{n})\\vec{n} \\]"},{"location":"GAMES101/Lecture%2017%20Materials%20and%20Appearances/#transmition","title":"Transmition","text":"<p>Snell's Law:</p> \\[ \\begin{align*} \\eta_i\\sin\\theta_i&amp;=\\eta_t\\sin\\theta_t \\\\[10pt] \\cos\\theta_t&amp;=\\sqrt{1-\\left(\\frac{\\eta_i}{\\eta_t}\\right)^2(1-\\cos^2\\theta_i)} \\end{align*} \\] <p>Snell's Window / Circle:</p> <p>Looking from underwater, can only see objects confined to a conical area.</p> <p>Fresnel Reflection / Term:</p> <p>Reflectance depends on incident angle (and polarization of light)</p> <p>Fresnel term (dieletric, \\(\\eta\\)=1.5):</p> <p>{style=\"width:350px\"}</p> <p>Approximate: Schlick's approximation</p> \\[ \\begin{align*} R(\\theta)&amp;=R_0+(1-R_0)(1-\\cos\\theta)^5 \\\\ R_0&amp;=\\left(\\frac{n_1-n_2}{n_1+n_2}\\right)^2 \\end{align*} \\]"},{"location":"GAMES101/Lecture%2017%20Materials%20and%20Appearances/#microfacet-material","title":"Microfacet Material","text":"<p>\u5047\u8bbe\u7269\u4f53\u8868\u9762\u7c97\u7cd9\uff0c\u4f46\u4ece\u8fdc\u5904\u770b\u8868\u9762\u5e73\u6ed1\u3002\u6bcf\u4e2a\u8868\u9762\u7684\u5fae\u5143\u5b8c\u5168\u955c\u9762\u53cd\u5c04\u3002 \uff08\u4ece\u8fdc\u5904\uff0c\u770b\u5230\u6750\u8d28\uff1b\u4ece\u8fd1\u5904\uff0c\u770b\u5230\u51e0\u4f55\uff09\u3002 \u8ba4\u4e3a\u8868\u9762\u7531\u5fae\u8868\u9762\u7ec4\u6210\uff0c\u6bcf\u4e2a\u5fae\u8868\u9762\u6709\u5404\u81ea\u7684\u6cd5\u7ebf\u3002</p> <p>\u5206\u6790\u5fae\u8868\u9762\u6cd5\u7ebf\u7684\u5206\u5e03\uff0c\u5224\u65ad\u5b8f\u89c2\u8868\u9762\u7684\u6750\u8d28\u3002 - concentrated &lt;-&gt; glossy - spread &lt;-&gt; diffuse</p> <p>\u5f53half vector\u548c\u6cd5\u7ebf\u76f8\u540c\u65f6\uff0c\u624d\u80fd\u5c06\u5165\u5c04\u5149\u53cd\u5c04\u5230\u5bf9\u7740\u76f8\u673a\u7684\u51fa\u5c04\u65b9\u5411\uff08\u56e0\u4e3a\u5fae\u8868\u9762\u90fd\u4e3a\u955c\u9762\u53cd\u5c04\uff09</p> \\[f(i,o)=F(i,h) G(i,o,h) D(h)\\] <p>f = Fresnel term * shadowing-masking term * distribution of normals</p>"},{"location":"GAMES101/Lecture%2017%20Materials%20and%20Appearances/#isotropic-anisotropic-materials","title":"Isotropic / Anisotropic Materials","text":"<p>(\u5404\u5411\u540c\u6027/\u5404\u5411\u5f02\u6027\u6750\u8d28)</p> <p>Key: directionality of underlying surface</p> <p>Anisotropic BRDFs: reflection depends on azimuthal angle \\(\\phi\\), results from oriented microstructure of surface.</p> \\[f_r(\\theta_i,\\phi_i;\\theta_r,\\phi_r)\\neq f_r(\\theta_i,\\theta_r,\\phi_r-\\phi_i)\\] <p>E.g. nylon, velvet</p>"},{"location":"GAMES101/Lecture%2017%20Materials%20and%20Appearances/#properties-of-brdfs","title":"Properties of BRDFs","text":"<ul> <li>Non-negativity</li> </ul> \\[ f_r(\\omega_i\\to\\omega_r)\\ge 0\\] <ul> <li>Linearity</li> </ul> \\[L_r(\\mathrm{p},\\omega_r)=\\int_{H^2}f_r(\\mathrm{p}, \\omega_i\\to\\omega_r)L_i(\\mathrm{p},\\omega_i)\\cos\\theta\\mathrm{d}\\omega_i\\] <ul> <li>Reciprocity principle</li> </ul> \\[f_r(\\omega_r\\to\\omega_i)= f_r(\\omega_i\\to\\omega_r)\\] <ul> <li>Energy conservation</li> </ul> \\[\\forall L_i\\int_{H^2}f_r(\\omega_i\\to\\omega_r)\\cos\\theta_i\\mathrm{d}\\omega_i\\le 1\\]"},{"location":"GAMES101/Lecture%2017%20Materials%20and%20Appearances/#measuring-brdfs","title":"Measuring BRDFs","text":"<p>For each outgoing direction and incoming direction, move light and camera.</p> <p>Problem: curse of dimensionality</p> <p>Improve efficiency:</p> <ul> <li>Isotropic surfaces reduce dimensionality from 4D to 3D  </li> <li>Reciprocity reduces # of measurements by half  </li> <li>Clever optical systems  </li> </ul> <p>MERL BRDF Database</p>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/","title":"Lec18 Advanced Topics in Rendering","text":""},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#advanced-light-transport","title":"Advanced Light Transport","text":"<p>Monte Carlo Estimators:</p> <ul> <li>Unbiased: the expected value will always be the correct value.</li> <li>Consistent: converges to the correct value</li> <li>Biased: not unbiased</li> </ul>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#bidirectional-path-tracing-bdpt","title":"Bidirectional Path Tracing (BDPT)","text":"<p>Traces sub-paths from both the camera and the light. Connects the end points from both sub-paths.</p> <p>BDPT is suitable if the light transport is complex on the light\u2019s side. e.g. the first step is diffusion.</p> <p>Cons: difficult to implement, slow</p>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#metropolis-light-transport-mlt","title":"Metropolis Light Transport (MLT)","text":"<p>Apply Markov Chain Monte Carlo (MCMC), jumping from the current sample to the next with some PDF.</p> <p>Very good at locally exploring difficult light paths.</p> <p>Key idea: locally perturb an existing path to get a new path</p> <p>Cons: difficult to estimate the convergence rate. Usually produces \u201cdirty\u201d results</p>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#photon-mapping","title":"Photon Mapping","text":"<p>Very good at handling Specular-Diffuse-Specular (SDS) paths and generating caustics</p> <ol> <li>photon tracing: Emitting photons from the light source, bouncing them around, then recording photons on diffuse surfaces</li> <li>photon collection: Shoot sub-paths from the camera, bouncing them around, until they hit diffuse surfaces</li> <li>local density estimation: For each shading point, fond the nearest N photons. Take the surfaces area they over.</li> </ol> <p>small N &lt;-&gt; noisy large N &lt;-&gt; blurry</p> <p>Why? local density estimation covers an area</p> <p>More photons emitted -&gt; the same N photons covers a smaller area</p> <ul> <li>Biased == blurry</li> <li>Consistent = not blurry with infinite samples</li> </ul>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#vertex-connection-and-merging-vcm","title":"Vertex Connection and Merging (VCM)","text":"<p>A combination of BDRT and Photon Mapping</p> <p>Key Idea:</p> <ul> <li>Not waste the sub-path in BDRT if their end points cannot be connected but can be merged</li> <li>Use photon mapping to handle the merging of nearby \u201cphotons\u201d</li> </ul>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#instant-radiosity-ir","title":"Instant Radiosity (IR)","text":"<p>Key Idea:</p> <ul> <li>Lit surfaces can be treated as light sources</li> </ul> <p>Approach:</p> <ul> <li>Shoot light sub-paths and assume the end point of each sub-path is a Virtual Point Light (VPL)</li> <li>Render the scene as usual using these VPLs</li> </ul> <p>Pros: fast and usually gives good results on diffuse scenes</p> <p>Cons:</p> <ul> <li>Spikes will emerge when VPLs are close to shading points</li> <li>Cannot handle glossy material</li> </ul>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#advanced-appearance-modeling","title":"Advanced Appearance Modeling","text":""},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#participating-media","title":"Participating Media","text":"<p>At any point as light travels through a participating medium, it can be (partially) absorbed and scattered. Use Phase Function to describe the angular distribution of light scattering at any point x within participating media.</p> <p>Rendering:</p> <ol> <li>Randomly choose a direction to bounce</li> <li>Randomly choose a distance to go straight</li> <li>At each \u201cshading point\u201d, connect to the light</li> </ol>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#hair-appearance","title":"Hair Appearance","text":"<p>Marschner Model:</p> <p>{style=\"width:300px\"}</p> <p>3 types of light interactions: R, TT, TRT (R: reflection; T: transmission)</p> <p>hair: cuticle -&gt; cortex -&gt; medulla (scatter light)</p> <p>Difference between hair/fur fibers: size of medulla</p> <p>Double Cylinder Model:</p> <p>{style=\"width:400px\"}</p> <p>{style=\"width:400px\"}</p>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#translucent-material","title":"Translucent Material","text":"<p>Subsurface scattering: Visual characteristics of many surfaces caused by light exiting at different points than it enters.</p> <p>BSSRDF: generalization of BRDF; exitant radiance at one point due to incident differential irradiance at another point</p> \\[S(x_i, \\omega_i, x_o, \\omega_o)\\] <p>Generalization of rendering equation: integrating over all points on the surface and all directions</p> \\[L(x_o,\\omega_o)=\\int_A\\int_{H^2} S(x_i, \\omega_i, x_o, \\omega_o)L_i(x_i,\\omega_i)\\cos\\theta_i\\mathrm{d}\\omega_i\\mathrm{d}A\\] <p>{style=\"width:350px\"}</p> <p>Dipole Approximation:approximate light diffusion by introducing two point sources</p>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#cloth","title":"Cloth","text":"<p>fiber -&gt; ply -&gt; yarn (woven or knitted) cloth</p> <p>Render as BRDF: given the weaving pattern, calculate the overall behavoir Limitation: cannot render velvet</p> <p>Render as Participating Media: properties of individual fibers and their distribution -&gt; scattering parameters</p> <p>Render as Actual Fibers...</p>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#detailed-apprearance","title":"Detailed Apprearance","text":"<p>Difficult path sampling problem: missing light Solution: BRDF over a pixel</p> <p>Recent Trend: Wave Optics</p>"},{"location":"GAMES101/Lecture%2018%20Advanced%20Topics%20in%20Rendering/#procedual-appearance","title":"Procedual Appearance","text":"<p>e.g. Define details without textures: compute a noise function on the fly.</p> <p>3D noise -&gt; internal structure if cut or broken</p>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/","title":"Lec19 Cameras, Lenses and Light Fields","text":"<p>Imaging = Synthesis + Capture</p>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/#field-of-view-fov","title":"Field of View (FOV)","text":"<p>{style=\"width:400px\"}</p> <p>For a fixed sensor size, decreaseing the focal length increses the FOV.</p> \\[\\text{FOV}=2\\,\\arctan\\left(\\frac{h}{2f}\\right)\\] <p>Due to historical reasons, the angle of view is usually expressed using the focal length of lenses designed for 35mm format film (36 x 24mm).</p> <ul> <li>17mm is a wide-angle lens, with a field of view of 104\u00b0</li> <li>50mm is a \"standard\" lens, with a field of view of 47\u00b0</li> <li>200mm is a telephoto lens, with a field of view of 12\u00b0</li> </ul>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/#exposure","title":"Exposure","text":"<p>\\(H=T\\times E\\) (Exposure = Time \\(\\times\\) Irradiance)</p> <p>Exposure time T: controlled by shutter Irradiance E: power of light falling on a unit area of sensor. Controlled by lens aperture and focal length.</p> <p>Aperture size</p> <ul> <li>Change the f-stop by opening / closing the aperture</li> </ul> <p>Shutter speed</p> <ul> <li>Change the duration the sensor pixels integrate light</li> </ul> <p>ISO gain</p> <ul> <li>Change the amplification (analog and/or digital) between sensor values and digital image values</li> </ul> <p>{style=\"width:500px\"}</p>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/#iso-gain","title":"ISO (Gain)","text":"<p>Third vaiable for exposure</p> <p>Film: trade sensitivity for grain Digital: trade sensitive for noise</p> <ul> <li>Multiply signal before analog-to-digital conversion  </li> <li>Linear effect (ISO 200 needs half the light as ISO 100)</li> </ul>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/#f-number-f-stop","title":"F-Number (F-Stop)","text":"<p>Written as FN or F/N. N is the f-number.</p> <p>Informal understanding: the inverse-diameter of a round aperture.</p> <p>Formal definition: the focal length divided by the diameter of the aperture.</p>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/#shutter","title":"Shutter","text":"<p>Motion blur: handshake, subject movement. Doubling shutter time doubles motion blur.</p> <p>Rolling shutter: different parts of photo taken at different times.</p> <p>If the exposure is to  bright/dark, may need to adjust f-stop and/or shutter up/down.</p> <p>Photograhers must trade off depth of field and motion blur for moving subjects.</p> <p>High-speed photography: extremely fase shutter speed x (large aperture and/or high ISO)</p>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/#thin-lens-approximation","title":"Thin Lens Approximation","text":"<p>We consider focal length can be arbitrarily changed (in reality, yes)</p> <p>Gaussian thin lens equation:</p> \\[\\frac{1}{f}=\\frac{1}{z_i}+\\frac{1}{z_o}\\] <p>(Why? Draw parallel ray and focal ray)</p>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/#defocus-blur","title":"Defocus Blur","text":"<p>Circle of Confusion (CoC)</p> <p>When the object is not on the focal plane, the image is not on the sensor plane. Sensor recieves a circle of light.</p> <p>C denotes the diameter of CoC. A denotes the diameter of lens.</p> <p>{style=\"width:450px\"}</p> \\[ \\frac{C}{A}=\\frac{d'}{z_i}=\\frac{|z_s-z_i|}{z_i}\\] \\[ C=A\\frac{|z_s-z_i|}{z_i}=\\frac{F}{N}\\frac{|z_s-z_i|}{z_i}\\] <p>Ray tracing for defocus blur</p> <ul> <li>Choose sensoe size, lens focal length and aperture size  </li> <li>Choose depth of subject of interest \\(z_o\\)</li> </ul>"},{"location":"GAMES101/Lecture%2019%20Cameras%2C%20Lenses%20and%20Light%20Fields/#depth-of-field","title":"Depth of Field","text":"<p>Depth range in a scene where the corresponding CoC is considered small enough.</p> <p>Depth of field: max depth range - min depth range</p>"},{"location":"GAMES101/games101/","title":"Lecture 01 / Overview of Computer Graphics","text":"<p>Menu of this lecture</p> <ul> <li>Concepts of raterization, ray tracing etc.</li> </ul>"},{"location":"GAMES101/games101/#basic-concepts","title":"Basic Concepts","text":"<p>Rasterization</p> <ol> <li>Project geometry primitives (3D triangles / polygons) onto the screen.</li> <li>Break projected primitives into fragments (pixels)</li> <li>Real-time applications is the gold standard in Video Games</li> </ol> translation <ol> <li>\u5c06\u51e0\u4f55\u5f62\u72b6\uff083D \u4e09\u89d2\u5f62/\u591a\u8fb9\u5f62\uff09\u6295\u5f71\u5230\u5c4f\u5e55\u4e0a</li> <li>\u5c06\u6295\u5f71\u540e\u7684\u56fe\u5143\u5212\u5206\u4e3a\u7247\u6bb5\uff08\u50cf\u7d20\uff09</li> <li>\u5728\u89c6\u9891\u6e38\u620f\u4e2d\uff0c\u5b9e\u65f6\u5e94\u7528\u662f\u9ec4\u91d1\u6807\u51c6</li> </ol> <p>Curves and Meshes</p> <p>Ray Tracing</p> <p>Shoot rays from camera through each pixel Offline application is the gold standard in Animation / Movies</p> <p>Animation / Simulation</p> <p>Difference between Computer Graphics and Computer Vision?</p> <p>{style=\"width:600px\"}</p> <p>Click here to jump to the course website</p>"},{"location":"GAMES101/games101/#lecture-02-review-of-linear-algebra","title":"Lecture 02 / Review of Linear Algebra","text":"<p>Menu of this lecture</p> <ul> <li>Functions of dot product and cross product</li> <li>Dot product and cross product in matrix</li> </ul> <p>Unit vector: \\(\\hat{a}=\\vec{a}/|\\vec{a}|\\) Usually use unit vectors to present directions.</p> <p>Vectors are represented as column vectors by default.</p>"},{"location":"GAMES101/games101/#functions-of-dot-product-and-cross-product","title":"Functions of dot product and cross product","text":"<p>Dot product:</p> <ol> <li>Find the angle between two vectors.    e.g cosine of angle bwtween light source and surface.</li> <li>Find projection of one vector on another.</li> </ol> <p>More specifically:</p> <ol> <li>Measure how close two directions are.</li> <li>Decompose a vector.</li> <li>Determine forward / backward.</li> </ol> <p>Cross product:</p> <ol> <li>Construction coordinate systems.</li> </ol> <p>Functions:</p> <ol> <li>Determine left / right. Given a plane and two vectors on this plane, determine the relative position of the two vectors.</li> <li>Determine in / out. Several vectors are connected head-to-tail to form a closed shape. Given another point, determine whether this point lies inside the closed shape.</li> </ol> <p>e.g. {style=\"width:100px\"} Check: \\(\\vec{AB}\\times\\vec{AP}, \\vec{BC}\\times\\vec{BP}, \\vec{CA}\\times\\vec{CP}\\). If the signs of all three are the same, then point P is inside the shape.</p>"},{"location":"GAMES101/games101/#dot-product-and-cross-product-in-matrix","title":"Dot product and cross product in matrix:","text":"<p>2D reflection about y-axis:</p> \\[ \\begin{pmatrix} -1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix}= \\begin{pmatrix} -x \\\\ y \\end{pmatrix} \\] matrix in latex <p><code>\\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix}</code></p> <p>Rendered output:</p> \\[ \\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix} \\] \\[ \\vec{a}\\cdot\\vec{b}=A^T\\cdot B =\\begin{pmatrix} x_a &amp; y_a &amp; z_a \\end{pmatrix} \\begin{pmatrix} x_b \\\\ y_b \\\\ z_b \\end{pmatrix} \\] \\[ \\vec{a}\\times\\vec{b}=A^*B =\\begin{pmatrix}  0 &amp; -z_a &amp; y_a \\\\  z_a &amp; 0 &amp; -x_a \\\\  -y_a &amp; x_a &amp; 0  \\end{pmatrix}  \\begin{pmatrix}  x_b \\\\ y_b \\\\ z_b  \\end{pmatrix} \\] <p>(\\(\\begin{pmatrix}   0 &amp; -z_a &amp; y_a \\\\  z_a &amp; 0 &amp; -x_a \\\\  -y_a &amp; x_a &amp; 0  \\end{pmatrix}\\) is the dual matrix of \\(\\vec{a}\\))</p>"},{"location":"GAMES101/games101/#lecture-03-transformation","title":"Lecture 03 / Transformation","text":"<p>Menu of this lecture</p> <ul> <li>2D transformations: rotation, scale, shear</li> <li>Homogeneous coordinates</li> <li>Composing transformation</li> </ul>"},{"location":"GAMES101/games101/#viewing-transformation","title":"Viewing transformation","text":"<p>Viewing transformation: 3D -&gt; 2D projection</p> <p>Scale</p> \\[ \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} =\\begin{pmatrix} s_x &amp; 0 \\\\ 0 &amp; s_y \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\] <p>Multiplying a matrix on the left corresponds to performing a row operation.</p> <p>Reflection</p> <p>E.g. reflection about the y-axis:</p> \\[ \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} =\\begin{pmatrix} -1 &amp; 0 \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\] <p>Sheer</p> <p>Illustration of sheer tranformation: {style=\"width:500px\"}</p> \\[ \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} =\\begin{pmatrix} x+ay \\\\ y \\end{pmatrix} =\\begin{pmatrix} 1 &amp; a \\\\ 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} \\] <p>Rotation</p> <p>By default, the rotation is around the origin. \\(R_{45}\\) refers to rotatiing 45 degrees counterclockwose about the origin. </p> \\[ R_{\\theta}=\\begin{pmatrix} \\cos\\theta &amp; -\\sin\\theta \\\\ \\sin\\theta &amp; \\cos\\theta \\end{pmatrix} \\]"},{"location":"GAMES101/games101/#homogeneous-coordinates","title":"Homogeneous Coordinates","text":"<p>Translation is not linear transform, so it cannot be represented in matrix form.  But we don't want it to be a special case, so homogeneous coordinates are used to represent all transformations. </p> <p>Add a third coordinate (w-coordinate), to represent the translation characters of points or vectors.  </p> <p>Affine transformations: affine map = linear map + translation map  </p> \\[ \\begin{pmatrix} x' \\\\ y' \\end{pmatrix} =\\begin{pmatrix} a &amp; b \\\\ c &amp; d \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} +\\begin{pmatrix} t_x \\\\ t_y \\end{pmatrix} \\]"},{"location":"GAMES101/games101/#2d-version","title":"2D version","text":"<ul> <li>2D point: \\(\\begin{pmatrix}x , y , 1 \\end{pmatrix}^T\\)</li> <li>2D vector:\\(\\begin{pmatrix}x , y , 0 \\end{pmatrix}^T\\)</li> </ul> <p>When \\(w\\neq 0\\), 2D point \\(\\begin{pmatrix}x , y , w \\end{pmatrix}^T\\) means \\(\\begin{pmatrix}x/w , y/w , 1 \\end{pmatrix}^T\\)</p> <p>(The w-coordinate of vectors are 0, which means vectors are translation invariant. By comparison, w-coordinate of points are 1)</p> <p>Use homogeneous Coordinates to represent affine translations:</p> \\[ \\begin{pmatrix} x' \\\\ y' \\\\ w' \\end{pmatrix} =\\begin{pmatrix} 1 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; t_y \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\\\ 1 \\end{pmatrix} =\\begin{pmatrix} x+t_x \\\\ y+t_y \\\\ 1 \\end{pmatrix} \\] <p>Properties:  1. The last row must be 0 0 1. 2. The top-left 2\u00d72 matrix represents a linear transformation. 3. The rightmost column represents translation. 4. Relations between points and vectors:    - vector + vector = vector    - point  - point  = vector    - point  + vector = point    - point  + point  = point</p> <p>Scale:</p> \\[ S(s_x, s_y)=\\begin{pmatrix} s_x &amp; 0 &amp; 0 \\\\ 0 &amp; s_y &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Rotation:</p> \\[ R(\\alpha)=\\begin{pmatrix} \\cos\\alpha &amp; -\\sin\\alpha &amp; 0 \\\\ \\sin\\alpha &amp; \\cos\\alpha &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Translation:</p> \\[ T(t_x, t_y)=\\begin{pmatrix} 1 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; t_y \\\\  0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Inverse transformations: \\(M^{-1}\\)</p> <p>Esp. matrix \\(R_{\\theta}\\) for rotation is orthogonal, so \\(R_{-\\theta}=R^{-1}=R^T\\).</p>"},{"location":"GAMES101/games101/#3d-version","title":"3D version","text":"<ul> <li>3D point: \\(\\begin{pmatrix}x , y , z, 1 \\end{pmatrix}^T\\)</li> <li>3D vector:\\(\\begin{pmatrix}x , y , z, 0 \\end{pmatrix}^T\\)</li> </ul> <p>Use 4\u00d74 matrix for affine transformations. </p>"},{"location":"GAMES101/games101/#composing-transforms","title":"Composing Transforms","text":"<p>All matrices are left-multiplied to the original coordinates, and are composed in the order of transformations from right to left.</p> <p>Examples</p> <p>Transformations: A1 -&gt; A2 -&gt; ... -&gt; An Matrix: \\(A_n\\cdots A_2A_1\\begin{pmatrix}x \\\\ y \\\\ 1\\end{pmatrix}\\)</p>"},{"location":"GAMES101/games101/#lecture-04-transformations-cont","title":"Lecture 04 Transformations Cont.","text":"<p>Menu of this lecture</p> <ul> <li>3D transformations</li> <li>Viewing transformations</li> </ul>"},{"location":"GAMES101/games101/#3d-transformations","title":"3D Transformations","text":"<p>Scale:</p> \\[ S(s_x, s_y, s_z)= \\begin{pmatrix} s_x &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; s_y &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; s_z &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Translation:</p> \\[ T(t_x, t_y, t_z)= \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; t_x \\\\ 0 &amp; 1 &amp; 0 &amp; t_y \\\\ 0 &amp; 0 &amp; 1 &amp; t_z \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\]"},{"location":"GAMES101/games101/#3d-rotations","title":"3D Rotations","text":""},{"location":"GAMES101/games101/#compose-from-r_x-r_y-r_z","title":"Compose from \\(R_x, R_y, R_z\\)","text":"\\[ R_x(\\theta)=\\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\cos\\theta &amp; -\\sin\\theta &amp; 0 \\\\ 0 &amp; \\sin\\theta &amp; \\cos\\theta &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] \\[ R_y(\\theta)=\\begin{pmatrix} \\cos\\theta &amp; 0 &amp; \\sin\\theta &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ -\\sin\\theta &amp; 0 &amp; \\cos\\theta &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>The rotation part of \\(R_y(\\theta)\\) is different from common rotation matrix, because \\(\\vec{y}=\\vec{z}\\times\\vec{x}\\), which is not the common sequence xyzxyz.</p> \\[ R_z(\\theta)=\\begin{pmatrix} \\cos\\theta &amp; -\\sin\\theta &amp; 0 &amp; 0 \\\\ \\sin\\theta &amp; \\cos\\theta &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>When rotating around x-, y-, and z- axis with angle \\(\\alpha, \\beta, \\gamma\\) respectively (\\(\\alpha, \\beta, \\gamma\\) are called Euler angles),  $$ R_{xyz}(\\alpha, \\beta, \\gamma)=R_x(\\alpha)R_y(\\beta)R_z(\\gamma) $$</p>"},{"location":"GAMES101/games101/#rodrigues-rotation-formation","title":"Rodrigues' Rotation Formation","text":"<p>Rotation by angle \\(\\alpha\\) around axis n, $$ R(n, \\alpha)=\\cos(\\alpha)I+(1-\\cos(\\alpha))n n^T+\\sin(\\alpha)\\begin{pmatrix} 0 &amp; -n_z &amp; n_y \\ n_z &amp; 0 &amp; -n_x \\ -n_y &amp; n_x &amp; 0 \\end{pmatrix} $$</p> <p>If the axis of rotation does not pass through the origin, first translate the entire system so that the axis passes through the origin, perform the rotation, and then translate the entire system back to its original position.</p> <p>Quaternions can be used for interpolation between rotation angles.</p>"},{"location":"GAMES101/games101/#viewing-transformations","title":"Viewing transformations","text":"<p>MVP Transformations:</p> <ol> <li>Model transformations (arrange objects and places)</li> <li>View transformations (arrange angles)</li> <li>Projection transformations</li> </ol>"},{"location":"GAMES101/games101/#define-camera","title":"Define camera","text":"<ul> <li>position: \\(\\hat{e}\\) (points from the origin to the camera)</li> <li>look-at / gaze direction: \\(\\hat{g}\\) (points from the camera to the object)</li> <li>up direction: \\(\\hat{t}\\)</li> </ul> <p>Usually we transform the camera to the origin, up at Y, look at -Z. And transform the objects along with the camera.</p>"},{"location":"GAMES101/games101/#transform-the-camera-mv-transformation","title":"Transform the camera (MV transformation)","text":"<p>Steps:</p> <ol> <li>Translate e to origin (\\(T_{view}\\))</li> <li>Rotate g to -Z, t to Y, (g, x, t) to x (\\(R_{view}\\))</li> </ol> <p>\\(T_{view}\\):</p> \\[ T_{view}= \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; -x_e \\\\ 0 &amp; 1 &amp; 0 &amp; -y_e \\\\ 0 &amp; 0 &amp; 1 &amp; -z_e \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>\\(R_{view}\\): Consider its inverse rotation (X to (g, x, t), Y to t, Z to -g).</p> <p>comment</p> <p>Both the direction and order of rotation must be reversed.</p> \\[ R_{view}^{-1}=\\begin{pmatrix} x_{\\hat{g}\\times\\hat{t}} &amp; x_t &amp; x_{-g} &amp; 0 \\\\ y_{\\hat{g}\\times\\hat{t}} &amp; y_t &amp; y_{-g} &amp; 0 \\\\ z_{\\hat{g}\\times\\hat{t}} &amp; z_t &amp; z_{-g} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\] <p>Since \\(R_{view}\\) is orthoganal,  \\(\\(R_{view}=(R_{view}^{-1})^T\\)\\)</p>"},{"location":"GAMES101/games101/#projection-transformation","title":"Projection transformation","text":"<p>Two 3D -&gt; 2D types: 1. orthographic projection 2. perspective projection</p>"},{"location":"GAMES101/games101/#orthographic-projection","title":"Orthographic projection","text":"<p>Consider a cuboid \\([l,r]\\times[b,t]\\times[f,n]\\), map it to the canonical cube \\([-1,1]^3\\), and drop Z coordinate to project.</p> Why we just need to drop Z coordinate? <p>In the \"Define camera\" part, we define the camera located at the origin, up at Y, look at -Z.</p> \\[ M_{ortho} = \\begin{pmatrix} \\frac{2}{r - l} &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; \\frac{2}{t - b} &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{2}{n - f} &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; -\\frac{r + l}{2} \\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{t + b}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{n + f}{2} \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\end{pmatrix} \\]"},{"location":"GAMES101/games101/#perspective-projection","title":"Perspective projection","text":"<p>Illustration:</p> <p>{style=\"width:400px\"}</p> <p>Steps: 1. Squish the frustum into a cuboid, all points on the near plane remain unchanged, all points on the far plane undergo in-plane contraction, with the center point of the far plane remaining fixed. 2. Do orthographic projection.</p> \\[ M_{persp\\to ortho}=\\begin{pmatrix} n &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; n &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; n+f &amp; -nf\\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\end{pmatrix} \\] Derivation <p>Squish illustration: {style=\"width:500px\"}  </p> \\[ M_{persp\\to ortho}\\begin{pmatrix}x\\\\y\\\\z\\\\1\\end{pmatrix} =\\begin{pmatrix}nx/z\\\\ny/z\\\\?\\\\1\\end{pmatrix} =\\begin{pmatrix}nx\\\\ny\\\\?\\\\z\\end{pmatrix} \\] <p>thus,</p> \\[ M_{persp\\to ortho}=\\begin{pmatrix} n&amp;0&amp;0&amp;0\\\\ 0&amp;n&amp;0&amp;0\\\\ A&amp;B&amp;C&amp;D\\\\ 0&amp;0&amp;1&amp;0 \\end{pmatrix} \\] <p>According to the properties of squishing, consider a point on the near plane and the middle point on the far plane to solve the third row.</p> <ol> <li>\\((x,y,n,1)\\to(x,y,n,1)=(nx,ny,n^2,n)\\) \\(n^2\\) is unrelated to x and y, thus \\(A=B=0, Cn+D=n^2\\)</li> <li>\\((0,0,f,1)\\to(0,0,f,1)=(0,0,f^2,f)\\) \\(Cf+D=f^2\\)</li> </ol> <p>Solve the equations above: \\(\\(C=n+f, D=-nf\\)\\)</p>"},{"location":"GAMES101/games101/#lecture-05-rasterization-1-triangles","title":"Lecture 05 Rasterization 1 (Triangles)","text":""},{"location":"GAMES101/games101/#lecture-06-rasterization-2-antiliasing-and-z-buffering","title":"Lecture 06 Rasterization 2 (Antiliasing and Z-Buffering)","text":""}]}