## CPU vs GPU

Differences:

- **CPU**: fewer cores, but each core is much faster and much more capable; has small cache while the majority of memory is in RAM; great at sequaltial tasks.
- **GPU**: more cores, but each core is much slower and "dumber"; has its own RAM built and cacheing system; great for parallel tasks (matrix multiplication, convolution, etc.).

Programming GPU: CUDA (cuDNN and other optimiazed APIs), OpenCL.

If you aren't careful, training can bottleneck on reading data and transfering to GPU! Solution: read all data from RAM; use SSD instead of HDD; use multiple CPU threads to prefetch data.

## Deep Learning Frameworks

One goal of deep learning frameworks: enable vectors to calculate on GPU, automatically do back propagation and gradient process...

### Tensorflow

Framework of Tensorflow:

```py
initialize N, D, H
x/y/w1/w2 = tf.placeholder(tf.float32, shape)

initialize h as x * w1
initialize y_pred as h * w2
set loss as Euclidien distance

grad_w1, grad_w2 = tf.gradients(loss, [w1, w2])

with tf.Session() as sess:
    set values as {x, w1, w2, y}
    initialize learing_rate
    for t in range(50):
        out = sess.run([loss, grad_w1, grad_w2], feed_dict = values)
        loss_val, grad_w1_val, grad_w2_val = out
        update values[w1] and values[w2]
```

Change w1 and w2 from `placeholder` to `Variable` (values live inside the graph) to avoid GPU bottlemeck. Tensorflow should use `assign` function to initialize them.

